[{"content":"Optimum Branchings 有向グラフ $G = (V, E)$ が与えられます．各辺には重みが与えられ，辺 $e$ の重みと辺集合の重みをそれぞれ $w(e)$, $w(E)$ で表します．\n$G$ の部分グラフ $G^{\\prime} = (V, E^{\\prime})$ のうち以下の 2 条件を満たすものを branching とよびます．\n閉路を含まない 同じ頂点に入る辺は高々 $1$ 本 すべての branching の中で $w(E^{\\prime})$ が最大のものを 最適 branching（optimum branching）とよびます12．\nこの問題は，最小全域木問題の有向辺バージョンである最小全域有向木問題と等価の問題で，互いに線形時間で変換することができます．\n下の図は有向グラフと対応する 最適 branching の例です．$G^{\\prime}$ の各コンポーネントは有向木なので，$G^{\\prime}$は有向森になります．\n以下ではいくつかの定義，補題，定理を確認したのち，最適 branching を求める Edmonds のアルゴリズムを説明します．\nこのアルゴリズムの計算量は $O(|E||V|)$ です．他にも $O(|E| \\log |V|)$ の Tarjan の実装や $O(|E| + |V| \\log |V|)$ の Gabow のアルゴリズムなどがあります．\nまた，最小重み有向木問題などのバリエーションを最適 Branching に帰着する方法と説明します．\n最後に実装例としてAOJ - 最小全域有向木の提出コードへのリンクをはっておきます．\n定義 critical 辺 $e = (u, v)$ が以下の 2 条件を満たすとき critical という．\n$w(e) \\gt 0$ $v$ に接続するすべての辺 $e^{\\prime}$ に対して，$w(e) \\ge w(e^{\\prime})$ $G$ の全域部分グラフ $H$ が以下の条件を満たすとき critical subgraph という．特にそれ以上辺を追加できない critical subgraph を maximal critical subgraph という．\n$H$ のすべての辺は critical $H$ の各頂点の入次数は高々 $1$ 下の図は maximal critical subgraph の例です．critical な辺を赤線で示しています．\neligible 辺 $e$ が入る頂点を $head(e)$ と表す．$G = (V, E)$ の branching $B$ に対して，$(B \\backslash \\lbrace (u, v) \\in B : v = head(e) \\rbrace) \\cup \\lbrace e \\rbrace$ も branching になるとき，$e$ を eligible という．\n補題 1 maximal critical subgraph $H$ は以下の性質を持ちます．\n各コンポーネントは高々 1 つの閉路をもち，閉路は互いに素 $H$ に閉路がなければ最適 branching 証明 頂点 $v$ が $2$ つの有向閉路上にあるとします．このとき，次数が少なくとも $2$ 以上の頂点が存在します．これは critical subgraph の条件に反します．\n$H$ に閉路がなければ $H$は branching です．任意の branching $B$ のすべての頂点 $v$ について以下が成り立ちます．\n$w(B \\cap \\lbrace e | head(e) = v \\rbrace) \\le w(H \\cap \\lbrace e | head(e) = v \\rbrace)$\nこれらをすべての頂点について足し合わせると $w(B) \\le w(H)$ となり，$H$ が最適となります．\n補題 2 辺 $e = (u, v) \\in E \\backslash B$ が eligible なことと，$B$ 上に $v$ から $u$ への有向パスがないことは同値\n証明 「辺 $e = (u, v) \\in E \\backslash B$ が eligible」なら「$B$ 上に $v$ から $u$ への有向パスがない」\n対偶として，$v$ から $u$ への有向パスがあるなら，$e$ は eligible ではないことを示します．\n$v$ から $u$ への有向パスがあるため，$(u, v)$ を追加すると閉路が発生します．\nこれは eligible の定義に反するため，$e$ は eligible ではありません．\n「$B$ 上に $v$ から $u$ への有向パスがない」なら「辺 $e = (u, v) \\in E \\backslash B$ が eligible」\n$e$ を $B$ に追加したとき，$(x, head(e)) \\in B$ の辺を削除すれば $v$ へ入る辺は高々 $1$ 本です．\nまた，$B$ には $v \\rightarrow u$ パスがないので，$e$ を追加しても閉路は発生しません．\nよって，$e$ は eligible です．\n補題 3 $B$ を $G = (V, E)$ の branching，$C$ を $G$ の有向サイクルとする．$C \\backslash B$ に eligible な辺がなければ， $|C \\backslash B| = 1$ となる\n証明 $C \\backslash B$ に eligible な辺がないとき，$|C \\backslash B|$ は 1 以外にならないことを示します．\n$|C \\backslash B| = 0$ にならない\n$B$ は branching なので起こりません\n$|C \\backslash B| = 2$ にならない\n$C \\backslash B = \\lbrace (s_1, t_1), (s_2, t_2) \\rbrace$ と仮定します．\nどちらの辺も eligible でないので，$B$ に $t_1$ から $s_1$ への有向パスと $t_2$ から $s_2$ への有向パスが存在します．\n$C$ は閉路なので，$t_2$ から $s_1$ への有向パスと $t_1$ から $s_2$ への有向パスは $C$ 上に存在します．\nよって，$B$ には，$t_2 \\rightarrow \\cdots \\rightarrow \\cdots s_1 \\rightarrow t_1 \\rightarrow \\cdots \\rightarrow s_2 \\rightarrow t_2$ のようなパスができます．\nこれは，$B$ の中に閉路があるということになり，$B$ が branching という仮定に矛盾します．\n$|C \\backslash B| = k \\gt 2$ にならない\n$|C \\backslash B| = 2$ に帰着します．\n定理 1 $G$ の maximal critical subgraph $H$ に対し，以下の最適 branching $B$ が存在する．\n$H$ に含まれるすべての有向閉路 $C_i$ について，$| C_i \\backslash B| = 1$． つまり，$H$ の各有向閉路からちょうど $1$ 本だけ辺が取り除かれているような最適 branching が存在するということです．\n下の図は $G$ に対する maximul critical subgraph $H$ と最適 branching です．\n$H$ の閉路から $(0, 1)$ と $(3, 5)$ を取り除いた最適 branching が存在することがわかります．\n証明 最適 branching のうち，$H$ の辺を最も多く含んでいるものを $B$ と仮定します．\n補題 2 により，$C \\backslash B$ に eligible な辺がなければ，$|C \\backslash B| = 1$ となるので，各 $C_i \\backslash B$ のすべての辺が eligible でないことを示します．\n$e \\in H \\backslash B$ が eligible であると矛盾が起きることを示します．\n$e$ は eligible なので，新しい branching $B^{\\prime} = \\lbrace B \\backslash \\lbrace e^{\\prime} \\rbrace \\rbrace \\cup \\lbrace e \\rbrace$ を作ることができます．ここで $e^{\\prime}$ は，$head(e)$ に入る $B$ 上の辺です．\nこのとき，$e \\in H$ であり，$e^{\\prime} \\notin H$ であるため，$B^{\\prime}$ は $B$ より多くの $H$ の辺を含みます．\nまた，$e$ は critical なので，$B^{\\prime}$ は最適 branching です．\nよって，$B$ より$H$ の辺を多く含む最適 branching $B^{\\prime}$ ができることとなり，これは仮定に矛盾します．\n定理 2 定理 1 を満たすような最適 branching $B$ に，以下の条件を満たす解が存在する．ここで $e^{0}_i$ は $C_i$ で最も重みの小さい辺である．\n各有向閉路 $C_i$ で $|C_i \\backslash B| = 1$ もし有向閉路 $C_i$ へ外部から入る辺が $B$ に存在しないなら，$C_i \\backslash B = \\lbrace e^{0}_i \\rbrace$ である． 証明 1.を満たす最適 branching の中で，$\\lbrace e^{0}_0, e^{1}_0, \\cdots, e^{0}_k \\rbrace$ が含まれる数がもっとも多いものを $B$ とします．\n$B$ には $C_i$ に外部から入る辺が存在しないにも関わらず，$C_i$ に $e^{0}_i$ が含まれていると仮定します．\n$C_i \\backslash B = \\lbrace e \\rbrace$ とします．\n$B^{\\prime} = (B \\backslash \\lbrace e^{0}_i \\rbrace) \\cup \\lbrace e \\rbrace$ とします．\nこの $B^{\\prime}$ は $\\lbrace e^{0}_i \\rbrace$ を含む最適 branching です． これは仮定と矛盾します．\nEdmonds のアルゴリズム グラフ $G = (V, E)$ の最適 branching を求める方法を考えます．表記上の都合のため多重辺はないものとします3．\nまず，maximal critical subgraph を求め，この辺集合を $H$ とします．\n補題 1 により $(V, H)$ が branching なら $(V, H)$ は最適 branching です．\n$(V, H)$ が branching でない場合を考えます．\nこの場合，$(V, H)$ には有向閉路が 1 つ以上存在します．\n定理 1 により，各閉路から 1 本辺を削除した辺集合を含む最適 branching $B^{\\star}$ が存在することがわかります．今後はこの $B^{\\star}$ を求めていきます．\n$B^{\\star}$ を求めるためには maximal critical graph の各閉路のどの辺を削除すればいいのかを考ます．\nもし，$B^{\\star}$ に（閉路の）外部から閉路に入る辺 $(u, v)$ がある場合，$v$ の入次数が $2$ になるのを避けるために閉路内で $v$ に入る辺を削除することになります．反対に，外部から閉路に入る辺がない場合，定理 2 より閉路内で最小の辺を削除することになります．\nつまり，閉路のどの辺を削除するかは閉路外部の辺構造によって決めることができます．そこで，閉路内部の辺構造（つまり，どの辺を削除するのか）を決めるより先に外部の辺構造を決めてしまいます．\nそのために，閉路外部の重みを適切に調整した上で閉路を $1$ つの超頂点に縮約します．この手続きによって得られるグラフを $G^{\\prime} = (V^{\\prime}, E^{\\prime})$ とします．\nこの $G^{\\prime}$ の最適 branching に超頂点に入る辺があるかどうかによって，$H$ の閉路のどの辺を削除するかを決めることができます．\n$G^{\\prime}$ の辺の重み $w^{\\prime}$ をどう設定するかを考えます．\n$G^{\\prime}$ の最適 branching から構成した $G$ の branching も最適 branching であるという条件を満たす必要があります．\nこのためには，任意の branching について，$w(B) = w^{\\prime}(B^{\\prime}) + const$ であることを示せればいいです．$B^{\\prime}$ と $B$ の重みの差は定数なので，$B^{\\prime}$ が最適なら $B$ も最適といえるためです．\n外部から閉路に入る辺を $e = (u, v)$，$v$ に入る閉路内唯一の辺を $\\tilde e$，閉路の最小の重みを持つ辺を $e^{0}$ とします． この条件を満たすためには，閉路に入る辺 $e$ の重みを $w^{\\prime}(e) = w(e) - w(\\tilde e) + w(e^{0})$ と設定すればいいです．\n閉路に入る辺以外の重みは $w$ のままとします．\n証明 $w(B) = w^{\\prime}(B^{\\prime}) + const$ となることを示します．\n$B^{\\prime}$ の超頂点を展開したときの重みの増加分を考えます．\n超頂点に入る辺 $e$ がないとき\n$e^{0}_i$ 以外の辺を採用するので，$w(C_i) - w(e^{0}_i)$ だけ増加します． 超頂点に入る辺 $e$ があるとき\n$w(\\tilde e)$ 以外の辺を採用するので，$w(C_i) - w(\\tilde e)$ だけ増加します．\nただし，$e$ の重みを $w^{\\prime}(e) = w(e) - w(\\tilde e) + w(e^{0}_i)$ と調整していたので，この調整を打ち消すと $w(C_i) - w(\\tilde e) - (- w(\\tilde e) + w(e^{0}_i)) = w(C_i) - w(e^{0}_i)$ となります．\n結局，$w(C_i) - w(e^{0}_i)$ だけ増加します． よって，どちらも $w(C_i) - w(e_i^{0})$ だけ増加するので，すべての閉路についてこの和をとると $w(B) = w^{\\prime}(B^{\\prime}) + \\sum_{i} w(C_i) - \\sum_{i} w(e_i^{0})$ となります．\n$\\sum_{i} w(C_i) - \\sum_{i} w(e^{0}_i)$ の部分は branching のとり方に依存しないため定数とみなすことができ，$w(B) = w^{\\prime}(B^{\\prime}) + const$ となります．\nこのように重みを設定した $G^{\\prime}$ に対し，最適 branching を求める手続きを再帰的に実行します．\n$G^{\\prime}$ は元のグラフより厳密に頂点数が少なくなるため，この手続きは有限回で終了します．\n$G$ の最適 branching $B$ は，この再帰呼び出しから返される $G^{\\prime}$ の最適 branching $B^{\\prime}$ に対して，閉路の $1$ 本を除いた残りすべての辺を加えることにより構築することができます．\n最後に計算量について考えます．\n1 回の手続きで少なくとも 1 つの頂点が減ります．1 回の手続きには $O(|E|)$ かかるので，このアルゴリズムの計算量は $O(|E||V|)$ です．\nEdmonds のアルゴリズムまとめ step 1: maximal critical subgraph の構築 maximal critical subgraph を求めます．この辺の集合を $H$ とします．\nstep 2: 閉路のチェック\n$(V, H)$ が branching を形成する場合，$(V, H)$ が最適 branching であるため，これを返します．\nstep 3: 閉路の縮約\n$H$ が $1$ つ以上の閉路を含む場合，任意の閉路 $C$ を選び，$C$ を $1$ つの超頂点 $a$​ に縮約します．\nこの操作によってできたグラフを $G^{\\prime} = (V^{\\prime}, E^{\\prime})$とします．ここで，$V^{\\prime} = (V \\backslash C) \\cup a$ です．\nstep 4: $G^{\\prime}$ における辺の重みの変更\n$C$ に入る辺： 辺 $(u \\notin C, v \\in C)$ に対して、$G^{\\prime}$ 内の新しい辺 $(u, a​)$ の重み $w^{\\prime}(u, a)$ を $w(u, v) - w(\\tilde e) + w(e^{0})$ とします．ここで，$w(\\tilde e)$ は $C$ に存在する頂点 $v$ に入る辺の重み，$w(e^{0})$ は $C$ に存在する辺の最小の重みです． $C$ から出る辺： 辺 $(u \\in C, v \\notin C)$ に対して、$G^{\\prime}$ 内の新しい辺 $(a, v)$ の重み $w^{\\prime}(a​, v)$ を $w(u, v)$ とします． $C$ に無関係な辺： 辺 $(u \\notin C,v \\notin C)$ に対して、$(u, v​)$ の重み $w^{\\prime}(u, v​)$ を $w(u, v)$ とします． step 5: 再帰呼び出し\n$G^{\\prime}$ の最適 branching を再帰的に見つけます．\nstep 6: 展開\n$G^{\\prime}$ の最適 branching が，閉路の外から超頂点 $a$​ に入る辺を持つ場合\n超頂点を展開します．$a$ に入る辺が展開後 $(u, v)$ であったとします．$C$ に含まれる辺のうち $v$ に入る辺以外の $|C| - 1$ 本を採用します．このようにして選んだ辺集合は最適 branching であるため，これを返します． $G^{\\prime}$ の最適 branching が，閉路の外から超頂点 $a$​ に入る辺を持たない場合\n超頂点を展開します．$C$ に含まれる辺のうち，最小の重みの辺以外の $|C| - 1$本を採用します．このようにして選んだ辺集合は最適 branching であるため，これを返します． アルゴリズムの実行例 下のグラフの branching を求めます．\nphase1 maximal critical subgraph を求めます．図では赤色の辺が対応します． 閉路のチェック $(2, 5), (5, 4), (4, 2)$ によって閉路が生じます． 閉路の縮約 閉路に属する頂点 $\\lbrace 2, 4, 5 \\rbrace$ を超頂点 $6$ に縮約します． 辺の重みの変更 超頂点に入る辺 $(0, 2)$ の重みを変更します．$2$ に入る閉路の辺の重みは $5$，閉路最小の重みは $4$ なので，$2 - 5 + 4 = 1$ となります． 超頂点に入る辺 $(3, 4)$ の重みを変更します．$4$ に入る閉路の辺の重みは $4$，閉路最小の重みは $4$ なので，$3 - 4 + 4 = 3$ となります． 再帰呼び出し 新しくできたグラフの最適 branching を求めます． phase2 maximal critical subgraph を求めます． 閉路のチェック $(1, 3), (3, 6), (6, 1)$ によって閉路が生じます． 閉路の縮約 閉路に属する頂点 $\\lbrace 1, 3, 6 \\rbrace$ を超頂点 $7$ に縮約します． 辺の重みの変更 超頂点に入る辺 $(0, 6)$ の重みを変更します．$6$ に入る閉路の辺の重みは $3$，閉路最小の重みは $1$ なので，$1 - 3 + 1 = -1$ となります． 再帰呼び出し 新しくできたグラフの最適 branching を求めます． phase3 maximal critical subgraph を求めます． 閉路のチェック 閉路が存在しないため，これは最適 branching です． phase4 ここからは閉路の展開をしていきます．\n現在は，$(7, 0)$ が branching の辺として選ばれています．\nbranching として選ばれた辺は青色の辺で示していきます．\nphase5 超頂点 $7$ を展開します．超頂点 $7$ は $(1, 3), (3, 6), (6, 1)$ からなる閉路でした．\nこの閉路に入る辺はないので，閉路のなかで最小の辺 $(6, 1)$ を除外し，$(1, 3), (3, 6)$ を採用します． phase6 超頂点 $6$ を展開します．超頂点 $6$ は $(2, 5), (5, 4), (4, 2)$ からなる閉路でした．\nこの閉路には $(3, 4)$ が入るので，閉路の中で $4$ に入る $(5, 4)$ を除外し，$(2, 5), (4, 2)$ を採用します．\nすべての閉路を展開をしたので，アルゴリズムを終了します．\n問題のバリエーション 以下の問題は，optimal branching と等価の問題であり，最適 branching のアルゴリズムを使って解くことができます．\n最小重み有向木問題（Minimum Weight Arborescence Problem） $G = (V, E)$ の全域有向森ではなく，全域有向木を求める問題です．木の根は任意になります．\n$G$ に全域有向木が存在すると仮定します．\n$G = (V, E)$ に対し，$K = 1 + \\sum_{e \\in E} |w(e)|$ とします．\n$w^{\\prime}(e) = K - w(e)$ と重みを変更した $G$ で最適 branching 問題を解きます．\n木 $B$ の辺の数を $|B|$ と表します．$|B| \\gt |B^{\\prime}|$ である任意の $2$ つの有向木 $B$，$B^{\\prime}$ に対して，$w^{\\prime}(B) - w^{\\prime}(B^{\\prime}) = (|B| - |B^{\\prime}|)K - (w(B) - w(B^{\\prime})) \\ge 0$ が成り立ちます．\nよって，$|B| \\gt |B^{\\prime}|$ ならば $w^{\\prime}(B) \\gt w^{\\prime}(B^{\\prime})$ であるため，最小重み有向木問題の解を求めることができます．\n最小重み根指定有向木問題（Minimum Weight Rooted Arborescence Problem）4 最小重み有向木問題で，全域木の根 $r$ が指定されている問題です．\n$G$ に $r$ を根とする全域有向木が存在すると仮定します．\n超頂点 $s$ を用意し，$G^{\\prime} = (V(G) \\cup \\lbrace s \\rbrace, E \\cup \\lbrace (s, r) \\rbrace)$，$w(s, r) = 0$ とします．\n$G^{\\prime}$ に対し，最小重み有向木問題の解を求め，$s$ を削除することで，最小重み根指定有向木問題の解を得ることができます．\n問題 AOJ - 最小全域有向木 提出コード 参考 Edmonds\u0026rsquo; algorithm Lecture notes: Graph Theory 2 GRAPH THEORY 3. Trees Handbook of Graph Theory, Combinatorial Optimization, and Algorithms 組合せ最適化 組合せ最適化では最大重み有向森問題（Maximum Weight Branching Problem）と表記されています\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n重みが最小の branching を求めたいときは重みの正負を反転します\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n辺を $(u, v)$ と表記したときに，一意に定めるためです\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n最小全域有向木問題，最小有向木問題とも\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-06-20T00:00:00+09:00","image":"https://miti-7.github.io/post/optimum-branchings-%E3%81%A8-edmonds-%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/images/branching%E3%81%AE%E4%BE%8B_hu_b315562712ba72eb.png","permalink":"https://miti-7.github.io/post/optimum-branchings-%E3%81%A8-edmonds-%E3%81%AE%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/","title":"Optimum Branchings と Edmonds のアルゴリズム"},{"content":"はじめに 厳密解を求める primal dual algorithm の話です．\nprimal dual algorithm の一般的な説明をしたあと，具体例としてハンガリアン法を導出します．\n準備 以下の等式標準形の線形計画問題を考えます．簡単のため $\\bold b \\ge 0$ を仮定します．\n主問題\n$$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\bold c^{T} \\bold x \\\\ \u0026\\text{subject to} \u0026\u0026 \\bold A \\bold x = \\bold b \\\\ \u0026 \u0026\u0026 \\bold x \\geq 0 \\end{aligned} $$ 双対問題 $$ \\begin{aligned} \u0026\\text{maxiimize} \u0026\u0026 \\bold b^{T} \\bold y \\\\ \u0026\\text{subject to} \u0026\u0026 \\bold A^{T} \\bold y \\leq \\bold c \\end{aligned} $$ $\\bold x$ と $\\bold y$ が主問題と双対問題の最適解であるための必要十分条件は，以下の 2 つの条件をともに満たすことです．\n$A_i$ は行列 $\\bold A$ の $i$行目を，$A^{j}$ は行列 $\\bold A$ の $j$ 列目の転置をとったものを表します．今回は主問題の制約条件に $\\bold A \\bold x = \\bold b$ があるため，双対相補性条件を常に満たします．\n主相補性条件\n$$ \\begin{aligned} \u0026\u0026 x_{j} \\gt 0 \\Rightarrow \\bold A^{j} \\bold y = c_{j} \u0026\u0026\u0026 \\forall j \\\\ \\end{aligned} $$ 双対相補性条件 $$ \\begin{aligned} \u0026\u0026 y_{i} \\gt 0 \\Rightarrow \\bold A_{i} \\bold x = b_{i} \u0026\u0026\u0026 \\forall i \\\\ \\end{aligned} $$ ${\\bold x}^{\\star}$ と ${\\bold y}^{\\star}$ が主問題と双対問題の最適解であるとき以下が成立します．\n$$ \\begin{aligned} \u0026\u0026 \\bold c^{T} \\bold x^{\\star} = \\bold b^{T} \\bold y^{\\star} \\\\ \\end{aligned} $$Primal Dual Algorithm primal dual algorithm は線形計画問題を解くための一般的なアルゴリズムです．\nprimal dual algorithm を用いて主問題の最適解 ${\\bold x}^{\\star}$ を求めます．簡単のため，主問題には実行可能解があると仮定します．primal dual algorithm は以下のように実行されます．双対問題の実行可能性が常に維持されていることに注意してください．\n双対問題の実行可能解 $\\bold y$ を求める $\\bold y$ をもとに構築した restricted primal problem を解く restricted primal problem の最適解の値が $0$ ならば，最適解 $\\bold {x}^{\\star}$ が判明したということなのでアルゴリズムを終了する restricted primal problem の最適解の値が $0$ でないならば，restricted primal problem の双対問題である dual restricted primal の最適解を求める．この解を $\\bold z$ とする ある $\\epsilon$ を求め，${\\bold y}^{\\prime} = {\\bold y} + \\epsilon {\\bold z}$ を新たな双対問題の実行可能解として採用し，2 に戻る 順に詳しくみていきます．\n双対問題の実行可能解 $\\bold y$ を適当に求めます．$\\bold c \\ge 0$ を仮定しているため $\\bold y = \\bold 0$ とおくことができます．\nある双対問題の解 $\\bold y$ が与えられたときに，「主問題の制約の違反」と「相補性条件の違反」を最小にするような主問題の解 $\\bold x$ を見 つける問題を考えます．もしこれらの違反量が 0 の $\\bold x$ を見つけることができたら，相補性条件よりこの $\\bold x$ と $\\bold y$ は最適解だということになります．\n$J = \\lbrace j \\mid \\bold A^{j} \\bold y = c_{j} \\rbrace$ とします．これは正になることのできる主問題の変数の index の集合です．すると，この問題は以下のような線形計画問題となります．これを restricted primal(以下 RP)とよびます．\nRestricted Primal $$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\sum_i s_i \\\\\\ \u0026\\text{subject to} \u0026\u0026 \\sum_{j \\in J} \\bold A_{ij} \\bold x_j + \\bold s_i = \\bold b_i \u0026\u0026\u0026 \\forall i\\\\\\ \u0026 \u0026\u0026 \\bold x \\geq \\bold 0 \u0026\u0026\u0026 j \\in J\\\\\\ \u0026 \u0026\u0026 \\bold x = \\bold 0 \u0026\u0026\u0026 j \\notin J\\\\\\ \u0026 \u0026\u0026 \\bold s \\geq \\bold 0 \\end{aligned} $$ もし RP の最適解の値が $0$ なら，この $(\\bold x, \\bold y)$ が主問題と双対問題の最適解ということになりアルゴリズムは終了します．\nそうでない場合は相補性条件を満たすような実行可能解 $\\bold x$ が見つからなかったということなので，$\\bold y$ は双対問題の最適解ではなかったということがわかります．\nそこで，$\\bold y$ よりも良い双対問題の解を探すことにします．\nそのために RP の双対問題である Dual Restricted Primal(以下 DRP)を考えます．これは以下のようになります．\nDual Restricted Primal $$ \\begin{aligned} \u0026\\text{maxmize} \u0026\u0026 \\bold b^{T} \\bold z \\\\\\ \u0026\\text{subject to} \u0026\u0026 \\bold A^{j} \\bold z \\leq 0 \u0026\u0026\u0026 j \\in J \\\\\\ \u0026 \u0026\u0026 z_{i} \\leq 1 \u0026\u0026\u0026 \\forall i \\\\\\ \\end{aligned} $$ DRP の最適解を $\\bold z^{\\star}$ とします． 双対問題の実行可能解 $\\bold y$ に $\\bold z^{\\star}$ を $\\epsilon(\\epsilon \\gt 0)$ 倍して足し合わせた解 ${\\bold y}^{\\prime} = \\bold y + \\epsilon \\bold z^{\\star}$ を考えます． 実はうまく $\\epsilon$ を選ぶことで $\\bold y^{\\prime}$ は元の解 $\\bold y$ よりも良い目的関数値をとり，さらに実行可能解となっています．\n$\\bold y$ よりも良い解 $\\bold y^{\\prime}$ が手に入れば，これを新たな双対問題の解として採用し，また 2 に戻り RP を考え\u0026hellip;と手順を繰り返していくことで，やがて最適解を得ることができます．\n最後に，$\\bold y^{\\prime} = \\bold y + \\epsilon \\bold z^{\\star}$ が解 $\\bold y$ よりも良い解となることと $\\bold y^{\\prime}$ が実行可能解となるような $\\epsilon$ の選び方を示します．\n$\\bold y^{\\prime} = \\bold y + \\epsilon \\bold z^{\\star}$ が解 $\\bold y$ よりも良くなることを示します．\n$\\bold y^{\\prime} = \\bold y + \\epsilon \\bold z$ を双対問題の目的関数に当てはめると $\\bold b^{T} \\bold y^{\\prime} = \\bold b^{T} \\bold y + \\epsilon \\bold b^{T} \\bold z^{\\star}$ となります．\n$\\epsilon \\bold b^{T} \\bold z^{\\star} \\gt 0$ となることを確認します．\n$\\epsilon$ は $0$ より大きい値をとるため，$\\epsilon \\gt 0$ となります．\nRP の最適解の値は 0 より大きかったため，その双対問題である DRP の最適解の値も 0 より大きいことになります．よって，$\\bold b^{T} \\bold z^{\\star} \\gt 0$ といえます．\n以上のことから，$\\bold y^{\\prime}$ が $\\bold y$ より良い目的関数値をとることがわかりました．\n$\\bold y^{\\prime} = \\bold y + \\epsilon \\bold z^{\\star}$ が双対問題の実行可能解となるような $\\epsilon$ の選び方を示します．\n双対問題の実行可能解になるように制約条件 $\\bold A^{T} \\bold y^{\\prime} \\leq \\bold c$ を満たすような $\\epsilon$ を求めます．\nまず，双対問題の制約条件より $\\bold A^{T} \\bold y \\le \\bold c$ です．\n次に，DRP の制約条件より $j \\in J$ については $\\bold A^{j} \\bold z^{\\star} \\le 0$ となります． よって，$j \\in J$ であるような $j$ については制約条件を満たすため，$j \\notin J$ のうち $\\bold A^{j} \\bold z^{\\star} \\gt 0$ である $j$ についてのみ考えます．\nこのような $j$ は $\\epsilon \\le \\min_{j \\notin J: A^{j} \\bold z^{\\star} \\gt 0} \\frac{c_j - \\bold A^{j} \\bold y}{\\bold A^{j} \\bold z^{\\star}}$ を満たす必要があります．\n$\\epsilon$ は大きい方がいいので，この条件を満たす最大の値を $\\epsilon$ として選びます．\nハンガリアン法 Primal Dual Algorighm を使ってハンガリアン法を導出します． 頂点 $a$ と頂点 $b$ を結ぶ辺を $(a, b) \\in E$ とし，その容量を $c_{ab}$ とします．簡単のため $\\bold c \\ge \\bold 0$ とし完全マッチングが存在するものとします．\n以下では，有向グラフを接続行列 $\\bold A$ で表します．また，ノードの数を $n$，辺の数を $m$ とします． 二部グラフの最小重み完全マッチングを線形緩和した主問題と双対問題を定義します．\n主問題 $$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\sum_{(a, b) \\in E} c_{ab} x_{ab} \\\\ \u0026\\text{subject to} \u0026\u0026 \\sum_{b:(a, b) \\in E} x_{ab} = 1 \u0026\u0026\u0026 a \\in A \\\\ \u0026 \u0026\u0026 \\sum_{a:(a, b) \\in E} x_{ab} = 1 \u0026\u0026\u0026 b \\in B \\\\ \u0026 \u0026\u0026 x_{ab} \\ge 0 \u0026\u0026\u0026 (a, b) \\in E\\\\ \\end{aligned} $$ 双対問題 $$ \\begin{aligned} \u0026\\text{maxiimize} \u0026\u0026 \\sum_{a \\in A} u_{a} + \\sum_{b \\in B} v_{b} \\\\ \u0026\\text{subject to} \u0026\u0026 u_{a} + v_{b} \\le c_{ab} \u0026\u0026\u0026 (a, b) in E\\\\ \\end{aligned} $$ハンガリアン法の導出 双対問題の適当な実行可能解を求めます．$C \\ge 0$ を仮定しているため，$\\bold u = \\bold v = \\bold 0$ とすることができます．\nrestricted primal を考えます．$J = \\lbrace(a, b) \\in E : u_{a} + v_{b} = c_{ab} \\rbrace$ とすると以下のようになります．これは $J$ の辺のみを使って完全マッチングを求める問題です．\nRestricted Primal $$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\sum_{a \\in A} s_{a} + \\sum_{b \\in B} s_{b} \\\\\\ \u0026\\text{subject to} \u0026\u0026 \\sum_{b:(a, b) \\in E} x_{ab} + s_{a} = 1 \u0026\u0026\u0026 a \\in A\\\\\\ \u0026 \u0026\u0026 \\sum_{a:(a, b) \\in E} x_{ab} + s_{b} = 1 \u0026\u0026\u0026 b \\in B\\\\\\ \u0026 \u0026\u0026 x_{ab} \u003e= 0 \u0026\u0026\u0026 (a, b) \\in J \\\\\\ \u0026 \u0026\u0026 x_{ab} = 0　\u0026\u0026\u0026 (a, b) \\in (E - J) \\\\\\ \u0026 \u0026\u0026 s \\ge 0 \\end{aligned} $$ $J$ の辺のみをつかって完全マッチングを作ることができれば，RP の目的関数値を 0 にすることができます． 辺の重みを考えなくてよくなったため，2 部グラフの最大マッチングを求めるアルゴリズムを使うことができます． もし完全マッチングがみつかればアルゴリズムは終了します．\n見つからない場合は dual restricted primal を考えます．DRP は $J$ の辺のみを使ったグラフ上で最小点被覆を求める問題です．これは RP で求めた最大マッチングの解を使って求めることができます ．\nDual Restricted Primal $$ \\begin{aligned} \u0026\\text{maximize} \u0026\u0026 \\sum_{a \\in A} u^{\\prime}_{a} + \\sum_{b \\in B} v^{\\prime}_{b} \\\\\\ \u0026\\text{subject to} \u0026\u0026 u^{\\prime}_{a} + v^{\\prime}_{b} \\le 0 \u0026\u0026\u0026 (a, b) \\in J \\\\\\ \u0026 \u0026\u0026 u^{\\prime}_{a} \\le 1 \u0026\u0026\u0026 a \\in A\\\\\\ \u0026 \u0026\u0026 v^{\\prime}_{b} \\le 1 \u0026\u0026\u0026 b \\in B \\end{aligned} $$ DRP の解を求め，$u^{\\prime \\prime} = u + \\epsilon u^{\\prime}$，$v^{\\prime \\prime} = v + \\epsilon v^{\\prime}$とします．ここで $\\epsilon = \\min_{(a, b) \\in (E - J)}(c_{ab} - u_{a} - v_{b})$ とすることができます．あとは，$u^{\\prime}$ と $v^{\\prime}$ を新しい双対問題の解として採用し，2 に戻ります．\n参考文系 Combinatorial Optimization: Algorithms and Complexity 18.433 Combinatorial Optimization The Primal-dual Algorithm CHAPTER 4 THE PRIMAL-DUAL METHOD FOR APPROXIMATION ALGORITHMS AND ITS APPLICATION TO NETWORK DESIGN PROBLEMS ","date":"2025-03-14T00:00:00+09:00","permalink":"https://miti-7.github.io/post/primal-dual-algorithm%E5%8E%B3%E5%AF%86%E8%A7%A3/","title":"Primal Dual Algorithm(厳密解)"},{"content":"ICL ICL 手術を アイクリニック東京 で受けてきました．\n日 event -43 診察の予約をする -31 初診適応検査をする -25 レンズ度数決定のための検査をする -21 レンズの準備完了の電話がくる．手術日，翌日検査，１週間後検査の予約をする -3 ～ -1 抗菌薬1を 1 日 4 回点眼する 0 手術日．手術前の抗菌薬点眼は朝と昼の 2 回行う．\n手術後に 3 種類の目薬2の点眼を開始 1 手術翌日検査をする．首から下のシャワーのみ可能 2 ～ 6 目薬2を 1 日 4 回点眼する．保護メガネ着用 7 手術 1 週間後検査をする 8 ～ 34 目薬3を 1 日 4 回点眼する．以降保護メガネは外していい 35 手術 1 ヶ月後検査をする 36 ～ 目薬4を 1 日 3 回点眼する． 93 手術 3 ヶ月後検査をする 初診適応検査 ICL を受けられるかの検査や視力の検査を行う 最初の問診票で執刀医の希望を書く欄があるので院長を指定した 検査結果は問題なかった 視力，屈折度，角膜曲率半径，眼圧検査の結果が貰える 全体で 80 分くらいかかった レンズ度数のシミュレーションをする．度数の強さと乱視補正をどうするかを次回までに決める 乱視付き ICL(トーリック ICL)にすると +5 万かかり，将来的に軸がずれ再手術しなければならない可能性がある 検査代として 1 万円支払うが，ICL を受ければ返ってくる レンズ度数決定のための検査 視力は前回の検査と変わらなかった 詳細なデータは貰えなかった レンズ度数の本決定 度数 PC を使う時間が多いので 2 段階強さを落としてもらった 具体的な強さを指定するのではなく，MAX から何段階落とすかを指定する形式だった 乱視補正 眼鏡では乱視補正をしているのと，軸がずれる可能性は低いということで乱視用のレンズにした 前金 30 万を払う 手術 病院 病院に到着後まず残金を支払い，その後の手術の説明をうける 瞳孔を開く目薬をさすので必要な手続きはすべて最初に行う 5 分ごとに目薬をする．スタッフが時間を教えてくれるわけではないので自分で時間を測る必要がある 時々スタッフが来て目の状態を確認する．結局 11 回ほど目薬をしたあとに手術室に呼ばれる 手術の最中は執刀医がどんな状況か教えてくれる 全部あわせて 5 分くらいで終わった 痛みはないが目に強い圧迫感があり精神的に厳しかった 全部で 2 時間くらいで終了した 帰宅後 目薬を 1 時間ごとにさす ハローとグレアがかなりすごい．マウスのカーソルにもハローが見える 目がゴロゴロする ひたすら目をつぶってはやめに寝た 翌日検査 体調 ハローとグレアはほぼないが真っ暗な部屋で白いモニターをみるとハローが少しみえる 目薬をさすときに目の周辺に黒い影がみえる．メガネの縁が見えているような感じ 病院で質問したらレンズの影とのこと そのうち脳内補正されて気にならなくなるらしい 目薬のときくらいしか見えないので日常生活に問題はなさそう 病院 眼圧検査，視力検査，検診をした 両目とも 1.5 になっていた 予定より視力があがってしまっていた 1 週間後検査 眼圧検査，視力検査，検診をした 特に問題なし 両目とも 1.5 のまま リンデロン点眼からフルメトロン点眼液 0.1% に変更 ドライアイがあるのでドライアイ用の目薬5を出してもらう 1 ヶ月後検査 眼圧検査，レンズのズレの検査，角膜内皮細胞数検査，視力検査，検診をした 特に問題なし 両目とも 1.5 のまま フルメトロン点眼液は使い切ったら終了で，クラビット点眼液とジクロフェナク Na 点眼液を 1 本ずつ処方された．これらを使い切ったら終了 問題がなく順調ですねと言われて一瞬で終わってしまった．細胞数がどうなっているのかとか聞いたら教えてもらえるのだろうか？ 3 ヶ月後検査 眼圧検査，レンズのズレの検査，角膜内皮細胞数検査，視力検査，検診をした 特に問題なし 両目とも 1.5 のまま レンズのズレもなく，傷口も完治しているとのことだった 必ず実施しないといけない検査は今回で終わり 6 ヶ月後検査や 1 年後検査はオプションらしい 3 年までの検査は無料 料金 73 万円 + 5 万円 - 2 万円 = 76 万円 基本料金：73 万円 乱視あり(片側のみ)：5 万円 平日割：-2 万円 料金がはっきりしているのはかなりよかった オプションを勧められるみたいな手間が一切なかった 懸念したこと レンズの回転（軸ずれ） トーリックレンズの場合はレンズの軸がずれると見え方が悪化してしまう（通常のレンズだと回転しても問題はない） 病院で軸がずれたときの見え方をシミュレーションしたがかなりきつい感じだった 軸ずれが起きる確率は 0.1 % くらいとのことなのでなにもないことに賭けた 3 年保証がありもし回転しても補正は無料なのと，どうしてもずれてしまうなら通常のレンズを入れ直そうと思っている 今のところ問題はない 気になったこと レンズ度数を決めたとき，どのレンズになるのかの書類が貰えず口約束になってしまっていた．今回は問題なかったけどトラブル防止に書類を貰っておけばよかった． そもそも書類を貰えるのか不明だが 手術前は丁寧なのだけど，手術後の検査はとにかくはやく終わらせよう感がすごい Google のレビューにも結構書いてある 全員がこういう態度なわけではなく，雑な人と丁寧な人がいる感じだった ベガモックス点眼液 0.5%\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nクラビット点眼液 1.5%，リンデロン点眼・点耳・点鼻液 0.1％，ジクロフェナク Na 点眼液 0.1%\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nクラビット点眼液 1.5%，フルメトロン点眼液 0.1%，ジクロフェナク Na 点眼液 0.1%\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nクラビット点眼液 1.5%，ジクロフェナク Na 点眼液 0.1%\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nヒアルロン酸ナトリウム点眼液 0.1％\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-02-24T00:00:00+09:00","permalink":"https://miti-7.github.io/post/icl%E3%82%92%E5%8F%97%E3%81%91%E3%81%A6%E3%81%8D%E3%81%9F/","title":"ICLを受けてきた"},{"content":"Quadratic Pseudo-Boolean Optimization 次の関数 $E(\\bold x)$ を最小化する問題を考えます．$x_{p} \\in \\lbrace 0, 1 \\rbrace$ とし，$\\theta_{const}$ は定数を表します．この問題を Quadratic Pseudo-Boolean Optimization(以下 QPBO)と呼びます．\n$$ \\begin{equation} E(\\bold x) = \\theta_{const} + \\sum_p \\theta_{p}(x_p) + \\sum_{p \\lt q} \\theta_{pq}(x_p, x_q) \\end{equation} $$競プロ界隈で「燃やす埋める」や「Project Selection Problem」などと言われる問題は QPBO に帰着することができます1．\nこれらの問題は minimum s-t cut に帰着して解くことができますが，どのように辺を張るかなど混乱しがちです．本記事の目的は QPBO を解くアルゴリズムをライブラリ化することで，問題を解くときに辺の張り方や変数のフリップ操作などを考えなくてすむようにすることです．実装は QPBO.hpp にあります．\n記事の構成は以下の通りです．\n節 1 では s-t cut と minimum s-t cut の説明をします．minimum s-t cut は多項式時間で求めることができます．\n節 2 では関数 $E(\\bold x)$ が $\\theta_{pq}(0, 0) = \\theta_{pq}(1, 1) = 0$ であり，どの関数も $0$ 以上の値を返すという単純な関数の場合について考えます． この場合は minimum s-t cut を見つける問題にそのまま帰着できます．\n節 3 では節 2 の仮定を排除し，関数 $E(\\bold x)$ が劣モジュラ関数であるという仮定のみをおいた場合について考えます．\nこの場合は再パラメータ化という操作を行うことで単純な関数の場合に帰着させることができます．\n節 4 では関数 $E(\\bold x)$ が一般の関数の場合について考えます．\n$E(\\bold x)$ が一般の関数の場合，これを最小化する問題は NP-hard であり，多項式時間で解くことは(今のところ)できそうもありません．この場合は問題を緩和することで劣モジュラ関数の場合に帰着させ近似解を得ることができます．さらに，ここで得られた解は最適解の一部となることが保証されます．\n節 5 では競プロの問題をいくつか解いていきます．\n1. s-t cut 頂点集合 $V$ と 有向辺 $E$ からなる有向グラフ $G = (V, E)$ が与えられます．辺 $(i, j)$ には容量 $c_{ij} \\ge 0$ が定まっているものとします．\n頂点集合 $V$ を 2 つの部分集合 $S$ と $T = V \\backslash S$ に分割します．2 つのノード $s$ と $t$ について $s \\in S$，$t \\in T$ となるような分割を s-t cut と呼びます．\n$S$ から出て $T$ に入るような辺の容量の総和を s-t cut の容量と呼び，以下で定義されます．すべての s-t cut のうち最小のものを minimum s-t cut と呼びます．\n$$ \\begin{aligned} c(S) = \\sum_{(i, j) \\in (S, T)} c_{ij} \\end{aligned} $$下のグラフの s-t cut の例をいくつか見ていきます 2．\n頂点の部分集合として，$S = \\lbrace s, 0, 1 \\rbrace$ を選んだとします．\n$S$ に属する頂点を赤，$T = V \\backslash S$ に属する頂点を青で示します． $S$ から出て $T$ に入るような辺は辺 (0, 2) と辺 (1, 3) です．よって，この s-t cut の容量は 3 + 2 = 5 となります．\nすべての s-t cut の中でこのカットより容量の小さい s-t cut は存在しないのでこれは minimum s-t cut です．\n頂点の部分集合として $S = \\lbrace s, 0, 1, 2, 3 \\rbrace$ を選んだとします．\nこの s-t cut の容量は 2 + 3 = 5 となります．\nこのカットも minimum s-t cut です．このように minimum s-t cut は複数存在することがあります．\n頂点の部分集合として $S = \\lbrace s, 1, 2 \\rbrace$ を選んだとします．\nこの s-t cut の容量は，3 + 2 + 4 + 2 = 11 となります．\n辺 (0, 1) や辺 (0, 2) は $T$ から $S$ に入る辺なので含まれません．\nminimum s-t cut は最大流問題を解き，残余ネットワーク上で頂点 $s$ から到達できる頂点集合を $S$ とすることで求められます．詳しくは 最大フロー最小カット定理 などを参照してください．\n次節から s-t cut を使って $E(\\bold x)$ を最小化する方法を見ていきます．\n2. 単純な関数の場合 関数 $E(\\bold x)$ を最小化する方法を考えていきます．$x_{p} \\in \\lbrace 0, 1 \\rbrace$ なので，変数の個数が $n$ 個のとき解は $2^n$ 個存在します．この $2^n$ 個の解のなかから最小のものを見つけるのが目標です．\n$$ \\begin{equation} E(\\bold x) = \\theta_{const} + \\sum_{p} \\theta_{p}(x_p) + \\sum_{p \\lt q} \\theta_{pq}(x_p, x_q) \\tag {1} \\end{equation} $$単純な関数の場合を考えたいので，$\\theta_{pq}(0, 0) = \\theta_{pq}(1, 1) = 0$ であり，すべて 0 以上の値を返すと仮定します．\nこの仮定を満たす関数の場合は $E(\\bold x)$ の解と s-t cut の解が 1 対 1 対応するようなグラフを作成することができます．よって，グラフの最小 s-t cut がわかれば $E(\\bold x)$ の最小値（= 最適解）を求めることができます．\nグラフは各変数を頂点とし，これに特別な頂点 $s$ と $t$ を加えた $n + 2$ 個の頂点から構成されます．辺は下記のルールにしたがって張ります．\n関数 辺 容量 $\\theta_{p}(0)$ $p \\rightarrow t$ $\\theta_{p}(0)$ $\\theta_{p}(1)$ $s \\rightarrow p$ $\\theta_{p}(1)$ $\\theta_{pq}(0, 1)$ $p \\rightarrow q$ $\\theta_{pq}(0, 1)$ $\\theta_{pq}(1, 0)$ $q \\rightarrow p$ $\\theta_{pq}(1, 0)$ 具体例として，変数が $a$ と $b$ の 2 つだけの場合を見てみます．\n各変数の値に対応する $E(\\bold x) = \\theta_a(a) + \\theta_b(b) + \\theta_{ab}(a, b)$ の値は以下のようになります．$\\theta_{ab}(0, 0)$ と $\\theta_{ab}(1, 1)$ の値は $0$ であり，$\\theta_{const}$ は定数のため省略しています．\na b $E(\\bold x)$ 0 0 $\\theta_{a}(0) + \\theta_{b}(0)$ 0 1 $\\theta_{a}(0) + \\theta_{b}(1) + \\theta_{ab}(0, 1)$ 1 0 $\\theta_{a}(1) + \\theta_{b}(0) + \\theta_{ab}(1, 0)$ 1 1 $\\theta_{a}(1) + \\theta_{b}(1)$ ルールに従うと下のグラフが構築されます．\nこのグラフの s-t cut をいくつか見ていきます．\n$S = \\lbrace s, a, b \\rbrace$ とします．この s-t cut の容量は $\\theta_{a}(0) + \\theta_{b}(0)$ です．\nまた，$a = 0$，$b = 0$ としたとき $E(\\bold x)$ の値は $\\theta_{a}(0) + \\theta_{b}(0)$ です．\nよって，$S = \\lbrace s, a, b \\rbrace$ としたときの s-t cut の容量と，$a = 0$，$b = 0$ としたときの $E(\\bold x)$ の関数値は一致しています．\n別の s-t cut の例をみます．\n$S = \\lbrace s, a \\rbrace$ とします．この s-t cut の容量は $\\theta_{a}(0) + \\theta_{b}(1) + \\theta_{ab}(0, 1)$ です．\nまた，$a = 0$，$b = 1$ としたとき $E(\\bold x)$ の値は $\\theta_{a}(0) + \\theta_{b}(1) + \\theta_{ab}(0, 1)$ です．\nよって，$S = \\lbrace s, a \\rbrace$ としたときの s-t cut の容量と，$a = 0$，$b = 1$ としたときの $E(\\bold x)$ の関数値は一致しています．\n変数が 2 つの場合は s-t cut は $2^2$ 通りあります．すべてのパターンは以下の通りです．\nこのように s-t cut の構成と $E(\\bold x) $ の構成が 1 対 1 対応するため，minimum s-t cut を計算することで $E(\\bold x)$ の最小値を求めることができます．\nminimum s-t cut を計算し，$S$ に属する頂点に対応する変数の値を $0$，$T$ に属する頂点に対応する変数の値を $1$ と設定することで最適な $\\bold x$ を構成できます．\n3. 劣モジュラ関数の場合 「2. 単純な関数の場合」では，$\\theta_{pq}(0, 0) = \\theta_{pq}(1, 1) = 0$ とし，どの関数も $0$ 以上の値を返すことを仮定していました．\nこの節ではこの仮定を排除し，関数は劣モジュラであることのみを仮定します．今回は 2 値変数を考えているので，$\\theta_{pq}(0, 1) + \\theta_{pq}(1, 0) \\ge \\theta_{pq}(0, 0) + \\theta_{pq}(1, 1)$ を満たすことになります．\n$\\theta_{pq}(0, 0)$ や $\\theta_{pq}(1, 1)$ が $0$ 以外の値をとったり関数値が負の値をとる場合があるので，今回はルール通りにグラフを作ることはできません．そこで再パラメータ化という操作を行います．再パラメータ化とは，$E(\\bold x)$ の関数値を保ちつつ $\\theta_{pq}(1, 0)$ などの各関数値を変化させる操作です．\n再パラメータ化を行うと標準形とよばれる以下の条件を満たす形になります3．標準形ではどの関数も $0$ 以上の値をとります．\n$min \\lbrace \\theta_{p}(0), \\theta_{p}(1) \\rbrace = 0$ $min \\lbrace \\theta_{pq}(0, 0), \\theta_{pq}(1, 0) \\rbrace = 0$ $min \\lbrace \\theta_{pq}(0, 1), \\theta_{pq}(1, 1) \\rbrace = 0$ 再パラメータ化をすると，関数 $\\theta_{pq}(x_{p}, x_{q})$ が劣モジュラの場合は $\\theta_{pq}(0, 0) = \\theta_{pq}(1, 1) = 0$ に，関数 $\\theta_{pq}(x_{p}, x_{q})$ が優モジュラの場合は $\\theta_{pq}(0, 1) = \\theta_{pq}(1, 0) = 0$ になります4．\nよって，すべての $\\theta_{pq}(x_{p}, x_{q})$ が劣モジュラ関数の場合は，再パラメータ化をすることで「2. 単純な関数の場合」に帰着することができます．\n再パラメータ化の手続きは以下の通りです．\nstep1 すべての (p, q) の各 $j \\in \\lbrace 0, 1 \\rbrace$ について $\\delta = min \\lbrace \\theta_{pq}(0, j), P_{pq}(1, j) \\rbrace$ $\\theta_{pq}(0, j) = \\theta_{pq}(0, j) - \\delta$ $\\theta_{pq}(1, j) = \\theta_{pq}(1, j) - \\delta$ $\\theta_{q}(j) = \\theta_{q}(j) + \\delta$ step2 $\\delta = min \\lbrace \\theta_p(0), \\theta_p(1) \\rbrace$ $\\theta_{p}(0) = \\theta_{p}(0) - \\delta$ $\\theta_{p}(1) = \\theta_{p}(1) - \\delta$ $\\theta_{const} = \\theta_{const} + \\delta$ 再パラメータ化をしたとき，目的関数値が変化しないことを確認します．\nstep 1 の $j = 0$ では，$\\theta_{pq}(0, 0)$ と $\\theta_{pq}(1, 0)$ から $\\delta$ を引き，$\\theta_{q}(0)$ に $\\delta$ を加えます．\nこの操作を行うと $E(\\bold x)$ は以下の表のように変化します．$\\delta$ が打ち消し合って，目的関数値が保たれていることが確認できます．\nまた，$\\delta$ として $min \\lbrace \\theta_{pq}(0, 0), P_{pq}(1, 0) \\rbrace$ を選んでいるので，$min \\lbrace \\theta_{pq;00}, \\theta_{pq;10} \\rbrace = 0$ を満たすようになります．\np q $E(\\bold x)$ $E^{\\prime}(\\bold x)$ 0 0 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(0) + \\theta_{ab}(0, 0)$ $\\theta_{const} + \\theta_{p}(0) + (\\theta_{q}(0) + \\delta) + (\\theta_{ab}(0, 0) - \\delta)$ 0 1 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(1) + \\theta_{ab}(0, 1)$ $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(1) + \\theta_{ab}(0, 1)$ 1 0 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(0) + \\theta_{ab}(1, 0)$ $\\theta_{const} + \\theta_{p}(1) + (\\theta_{q}(0) + \\delta) + (\\theta_{ab}(1, 0) - \\delta)$ 1 1 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(1) + \\theta_{ab}(1, 1)$ $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(1) + \\theta_{ab}(1, 1)$ step 1 の $j = 1$ では，$\\theta_{pq}(0, 1)$ と $\\theta_{pq}(1, 1)$ から $\\delta$ を引き，$\\theta_{q}(1)$ に $\\delta$ を加えます．\n$\\delta$ として $min \\lbrace \\theta_{pq}(0, 1), P_{pq}(1, 1) \\rbrace$ を選んでいるので，$min \\lbrace \\theta_{pq;01}, \\theta_{pq;11} \\rbrace = 0$ を満たすようになります．\np q $E(\\bold x)$ $E^{\\prime}(\\bold x)$ 0 0 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(0) + \\theta_{ab}(0, 0)$ $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(0) + \\theta_{ab}(0, 0)$ 0 1 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(1) + \\theta_{ab}(0, 1)$ $\\theta_{const} + \\theta_{p}(0) + (\\theta_{q}(1) + \\delta) + (\\theta_{ab}(0, 1) - \\delta)$ 1 0 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(0) + \\theta_{ab}(1, 0)$ $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(0) + \\theta_{ab}(1, 0)$ 1 1 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(1) + \\theta_{ab}(1, 1)$ $\\theta_{const} + \\theta_{p}(1) + (\\theta_{q}(1) + \\delta) + (\\theta_{ab}(1, 1) - \\delta)$ step 2 では，$\\theta_{p}(0)$ と $\\theta_{p}(1)$ から $\\delta$ を引き，$\\theta_{const}$ に $\\delta$ を加えます．\n$\\delta$ として $min \\lbrace \\theta_p(0), \\theta_p(1) \\rbrace$ を選んでいるので，$min \\lbrace \\theta_{p;0}, \\theta_{p;1} \\rbrace = 0$ を満たすようになります．\np q $E(\\bold x)$ $E^{\\prime}(\\bold x)$ 0 0 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(0) + \\theta_{ab}(0, 0)$ $(\\theta_{const} + \\delta) + (\\theta_{p}(0) - \\delta) + \\theta_{q}(0) + \\theta_{ab}(0, 0)$ 0 1 $\\theta_{const} + \\theta_{p}(0) + \\theta_{q}(1) + \\theta_{ab}(0, 1)$ $(\\theta_{const} + \\delta) + (\\theta_{p}(0) - \\delta) + \\theta_{q}(1) + \\theta_{ab}(0, 1)$ 1 0 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(0) + \\theta_{ab}(1, 0)$ $(\\theta_{const} + \\delta) + (\\theta_{p}(1) - \\delta) + \\theta_{q}(0) + \\theta_{ab}(1, 0)$ 1 1 $\\theta_{const} + \\theta_{p}(1) + \\theta_{q}(1) + \\theta_{ab}(1, 1)$ $(\\theta_{const} + \\delta) + (\\theta_{p}(1) - \\delta) + \\theta_{q}(1) + \\theta_{ab}(1, 1)$ 4. 一般の関数の場合 関数に何も仮定を置かない場合は $E(\\bold x)$ の最小化は NP-hard なので，minimum s-t cut 問題に帰着できない場合があります．\nこの場合でも最適解はだせなくても問題を解けるだけ解く QPBO 法というアルゴリズムがあります5．QPBO 法は解として $x_p = \\lbrace 0, 1, \\emptyset \\rbrace$ のいずれかを与えます．$\\emptyset$ は解が不明であることを表します．$x_p$ に $0$ か $1$ の値が与えられたとき，$x_p$ はラベル付けされたといいます．\nこのアルゴリズムは次のような性質があります．\nアルゴリズムの出力を $\\bold x$ とする．完全にラベル付けされた任意の解 $\\bold y$ があるとき，以下のように $\\bold z$ を定めると常に $E(\\bold z) \\le E(\\bold y)$ を満たす． $$ z_p = \\left\\{ \\begin{array}{ll} x_p \u0026 \\text{if} \\space x_p \\in \\lbrace 0, 1 \\rbrace \\\\ y_p \u0026 \\text{if} \\space x_p = \\emptyset \\end{array} \\right. $$ 関数のすべての項が劣モジュラのとき最適解が求まる． アルゴリズムはフリップ操作に対して不変である． 性質 1 で $\\bold y$ に最適解を選べば $\\bold x$ は常に最適解の一部となることがわかります．\n競プロで役に立つのは性質 2 と 3 です．この 2 つの性質から，すべての項を劣モジュラにするようなフリップ操作がある場合に QPBO 法は最適解を求めることがわかります．\nQPBO 法を説明します．\n以降は表記が煩雑になるのを避けるためこの節では関数値を以下のように表記することがあります．\n$\\theta_{p}(0)$ $\\theta_{p;0}$ $\\theta_{p}(1)$ $\\theta_{p;1}$ $\\theta_{pq}(0,0)$ $\\theta_{pq;00}$ $\\theta_{pq}(0,1)$ $\\theta_{pq;01}$ $\\theta_{pq}(1,0)$ $\\theta_{pq;10}$ $\\theta_{pq}(1,1)$ $\\theta_{pq;11}$ 各変数 $x_p$ に対して，$x_{\\bar{p}} = 1 - x_{p}$ を導入し，$E(\\bold x) = \\sum \\theta_{p}(x_p) + \\sum \\theta_{pq}(x_p, x_q)$ を変形します．\n$$ \\begin{alignedat}{2} E(\\bold x) \u0026= \\theta_{const} + \\sum \\theta_{p}(x_p) \u0026\u0026+ \\sum \\theta_{pq}(x_p, x_q) \\\\ \u0026= \\theta_{const} + \\sum \\big( \\theta_{p;1} x_{p} + \\theta_{p;0}(1 - x_{p}) \\big) \\\\ \u0026\\quad \u0026\u0026+ \\sum \\big( \\theta_{pq;00} (1 - x_{p})(1 - x_{q}) \\\\ \u0026\\quad \u0026\u0026\\quad + \\theta_{pq;01} (1 - x_{p}) x_{q} \\\\ \u0026\\quad \u0026\u0026\\quad + \\theta_{pq;10} x_{p}(1 - x_{q}) \\\\ \u0026\\quad \u0026\u0026\\quad + \\theta_{pq;11} x_{p} x_{q} \\big) \\\\ \u0026= \\theta_{const} + \\sum \\bigg( \\frac{\\theta_{p;1}}{2}(x_p + (1 - x_{\\bar{p}})) \u0026\u0026 + \\frac{\\theta_{p;0}}{2}(x_{\\bar{p}} + (1 - x_p)) \\bigg) \\\\ \u0026\\quad \u0026\u0026+ \\sum \\bigg( \\frac{\\theta_{pq;00}}{2} \\big(x_{\\bar{p}} (1 - x_q) + (1 - x_p) x_{\\bar{q}} \\big) \\\\ \u0026\\quad \u0026\u0026\\quad + \\frac{\\theta_{pq;01}}{2} \\big((1 - x_p) x_q + x_{\\bar{p}} (1 - x_{\\bar{q}}) \\big) \\\\ \u0026\\quad \u0026\u0026\\quad + \\frac{\\theta_{pq;11}}{2} \\big(x_p (1 - x_{\\bar{q}}) + (1 - x_{\\bar{p}}) x_q \\big) \\\\ \u0026\\quad \u0026\u0026\\quad + \\frac{\\theta_{pq;10}}{2} \\big(x_p (1 - x_q) + (1 - x_{\\bar{p}}) x_{\\bar{q}} \\big) \\bigg) \\end{alignedat} $$ここで，$x_{\\bar{p}} = 1 - x_p$ という制約を緩和し，$x_p$ と $x_{\\bar{p}}$ が独立に値をとれる緩和問題を考えます．\n各変数の係数を比較すると下の関数に分割できることがわかります． 再パラメータ化をしてから関数を分割することですべての関数値が $0$ 以上であることが保証されます．これらの関数は劣モジュラ関数なので「3. 劣モジュラ関数の場合」に帰着することができます．\n$x_p$ 0 $\\frac{1}{2}\\theta_{p;0}$ 1 $\\frac{1}{2}\\theta_{p;1}$ $x_{\\bar{p}}$ 0 $\\frac{1}{2}\\theta_{p;1}$ 1 $\\frac{1}{2}\\theta_{p;0}$ $x_p$ $x_q$ 0 0 0 0 1 $\\frac{1}{2}\\theta_{pq;01}$ 1 0 $\\frac{1}{2}\\theta_{pq;10}$ 1 1 0 $x_p$ $x_{\\bar{q}}$ 0 0 0 0 1 $\\frac{1}{2}\\theta_{pq;00}$ 1 0 $\\frac{1}{2}\\theta_{pq;11}$ 1 1 0 $x_{\\bar{p}}$ $x_q$ 0 0 0 0 1 $\\frac{1}{2}\\theta_{pq;11}$ 1 0 $\\frac{1}{2}\\theta_{pq;00}$ 1 1 0 $x_{\\bar{p}}$ $x_{\\bar{q}}$ 0 0 0 0 1 $\\frac{1}{2}\\theta_{pq;01}$ 1 0 $\\frac{1}{2}\\theta_{pq;10}$ 1 1 0 上記関数について，ルールに従ってグラフを構築します． 整理すると以下のルールに従ってグラフを構築すればいいことがわかります．\n$\\theta$ edge capacity6 $\\theta_{p;0}$ $(p \\rightarrow t), (s \\rightarrow \\bar p)$ $\\frac{1}{2} \\theta_{p;0}$ $\\theta_{p;1}$ $(s \\rightarrow p), (\\bar p \\rightarrow t)$ $\\frac{1}{2} \\theta_{p;1}$ $\\theta_{pq;01}$ $(p \\rightarrow q), (\\bar q \\rightarrow \\bar p)$ $\\frac{1}{2} \\theta_{pq;01}$ $\\theta_{pq;10}$ $(q \\rightarrow p), (\\bar p \\rightarrow \\bar q)$ $\\frac{1}{2} \\theta_{pq;10}$ $\\theta_{pq;00}$ $(p \\rightarrow \\bar q), (q \\rightarrow \\bar p)$ $\\frac{1}{2} \\theta_{pq;00}$ $\\theta_{pq;11}$ $(\\bar q \\rightarrow p), (\\bar p \\rightarrow q)$ $\\frac{1}{2} \\theta_{pq;11}$ このグラフの s-t minimum cut を計算します．各変数の値は，$S$ に属する場合は 0，$T$ に属する場合は 1 をとります．ただし，$x_{\\bar{p}} = 1 - x_{p}$ という制約を満たす必要があります．よって，$\\bold x$ は次のように構成されます．\n$$ x_{p} = \\left\\{ \\begin{array}{ll} 0 \u0026 \\text{if} \\space p \\in S, \\bar p \\in T \\\\ 1 \u0026 \\text{if} \\space p \\in T, \\bar p \\in S \\\\ \\emptyset \u0026 \\text{otherwise} \\end{array} \\right. $$具体例として，変数が $a$ と $b$ の 2 つだけの場合を考えます．\n各変数の値に対応する $E(\\bold x) = \\theta_a(a) + \\theta_b(b) + \\theta_{ab}(a, b)$ の値は以下のようになります．\na b $E(\\bold x)$ 0 0 $\\theta_{a}(0) + \\theta_{b}(0) + \\theta_{ab}(0, 0)$ 0 1 $\\theta_{a}(0) + \\theta_{b}(1) + \\theta_{ab}(0, 1)$ 1 0 $\\theta_{a}(1) + \\theta_{b}(0) + \\theta_{ab}(1, 0)$ 1 1 $\\theta_{a}(1) + \\theta_{b}(1) + \\theta_{ab}(1, 1)$ 対応するグラフは以下のようになります．表記が煩雑になるので図では $\\frac{1}{2}$ を除外しています．このグラフの s-t cut の例をいくつか見ていきます．\n$S = \\lbrace s, a, b \\rbrace$ とします．この s-t cut の容量は $\\frac{1}{2} (\\theta_{a}(0) + \\theta_{a}(0) + \\theta_{b}(0) + \\theta_{b}(0) + \\theta_{ab}(0, 0) + \\theta_{ab}(0, 0))$ です．\nこの値は $a = 0$，$b = 0$ としたときの $E(\\bold x)$ の目的関数と一致します．\n$S = \\lbrace s, a \\rbrace$ とします．この s-t cut の容量は $\\frac{1}{2} (\\theta_{a}(0) + \\theta_{a}(0) + \\theta_{b}(1) + \\theta_{b}(1) + \\theta_{ab}(0, 1) + \\theta_{ab}(0, 1))$ です．\nこの値は $a = 0$，$b = 0$ としたときの $E(\\bold x)$ の目的関数と一致します．\n$S = \\lbrace s, a, b, \\bar{b} \\rbrace$ とします．この場合，$a = 0$，$b = \\emptyset$ とし，$b$ のラベルは未定となります．\n5. 問題 QPBO を使って競プロの問題を解いていきます．\nARC085 E - MUL 宝石が $N$ 個あり，それぞれ $1,2,\\cdots,N$ と数が書かれています。\nあなたは，以下の操作を好きなだけ行うことが出来ます(一度も行わなくてもよいです)。\n正整数 $x$ を選ぶ。$x$ の倍数が書かれた宝石を全て叩き割る。 そして，$i$ が書かれていた宝石が割られずに残っていた場合，$a_i$ 円貰います。 ただし，この $a_i$ は負の場合もあり，その場合はお金を払わなくてはいけません。\nうまく操作を行った時，あなたは最大で何円お金を貰えるでしょうか？\nまず変数を定義します．\n宝石 $i$ が残っているかどうかを $x_i$ で表します．宝石が割る場合 $1$ を，残す場合は $0$ をとります．\n次に関数を定義します．\nQPBO は目的関数値の最小化を目指すのでコストがいくらかかるかで表します．\n宝石 $i$ が残っている場合 $a_i$ 円貰えます．これは $-a_i$ 円のコストを払うということなので，次のように定義できます．\n$\\theta_{i}(0) = -a_i$ $\\theta_{i}(1) = 0$ また，宝石 $i$ を割るにもかかわらず $i$ で割り切れる値が書かれた宝石 $j$ を残すことは許されないので，この場合は無限のコストがかかるとします．よって，次のように定義できます．\n$\\theta_{ij}(0, 0) = 0$ $\\theta_{ij}(0, 1) = 0$ $\\theta_{ij}(1, 0) = \\infty$ $\\theta_{ij}(1, 1) = 0$ この関数は $\\theta_{ij}(0, 1) + \\theta_{ij}(1, 0) \\ge \\theta_{ij}(0, 0) + \\theta_{ij}(1, 1)$ を満たしているので劣モジュラ関数です．\nあとは，すべての $i$ と $i$ で割り切れる $j$ について上記関数を定義すれば問題を解くことができます．\n提出コード\nABC193 F - Zebraness 縦 $N$ マス、横 $N$ マスのマス目があります。上から $i$ 行目、左から $j$ 列目のマスをマス $(i,j)$ と表すことにします。 マス $(i,j)$ の色の情報が文字 $c_{i,j}$ により与えられます。\n$B$ はマスが黒で塗られていることを、 $W$ はマスが白で塗られていることを、 $?$ はマスにまだ色が塗られていないことを表します。\n高橋くんは、まだ色が塗られていないマスをそれぞれ黒または白で塗り、白黒のマス目を作ります。マス目のしまうま度を、辺で接する黒マスと白マスの組の個数と定義します。高橋くんが達成できるしまうま度の最大値を求めてください。\nまず変数を定義します．\nマスを $(i, j)$ で表すとすると関数が見にくいので $p = i \\times N + j$ で表します． マス $p$ の色を変数 $x_{p}$ で表します．白の場合 $0$ をとり，黒の場合 $1$ をとります．\n次に関数を定義します．\n与えられている色の変更はできないので白から黒や黒から白に変更すると無限のコストがかかるとします．次のように定義できます．\nマス $p$ の色が黒の場合\n$\\theta_{p}(0) = \\infty$ $\\theta_{p}(1) = 0$ マス $p$ の色が白の場合\n$\\theta_{p}(0) = 0$ $\\theta_{p}(1) = \\infty$ マス $p$ と辺で接するマス $q$ が異なる色だと -1 のコストがかかります．\n$\\theta_{pq}(0, 0) = 0$ $\\theta_{pq}(0, 1) = -1$ $\\theta_{pq}(1, 0) = -1$ $\\theta_{pq}(1, 1) = 0$ これは劣モジュラ関数ではないのですが，変数フリップすることで劣モジュラ関数にすることができます． QPBO 法では変数フリップを考慮しなくていいのでそのまま定義することができます．\n提出コード\nその他の問題 No.2713 Just Solitaire 提出コード AOJ - Board 提出コード AOJ - Ghost 提出コード 競プロ典型 90 問 040 - Get More Money（★7） 提出コード ABC259 G - Grid Card Game 提出コード 参考 Minimizing non-submodular functions with graph cuts – a review 劣モジュラ最適化と機械学習 Graph cut optimization Quadratic pseudo-Boolean optimization たぶんです．できない例があったら教えてください\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nこの数値例は最大フロー最小カット定理から引用しています\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n標準形は一意に定まるとは限りません\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n単純な関数の場合は劣モジュラ関数を(ほぼ)標準化したものでした．厳密には $min \\lbrace \\theta_{p;0}, \\theta_{p;1} \\rbrace = 0$ を満たしていませんが．\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMinimizing non-submodular functions with graph cuts – a review\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n実装では容量に $\\frac{1}{2}$ をかけるのではなく，最後に目的関数値に $\\frac{1}{2}$ を掛ければいいです\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2025-01-09T00:00:00+09:00","image":"https://miti-7.github.io/post/quadratic-pseudo-boolean-optimization/images/general_sample_ab_1_hu_1a7e1bfab21a6145.png","permalink":"https://miti-7.github.io/post/quadratic-pseudo-boolean-optimization/","title":"Quadratic Pseudo-Boolean Optimization"},{"content":"設定 Kinesis Advantage 360 Pro の設定をメモしておきます\nバックライト デフォルトだと「Mod + Enter」で on/off，「Mod + ↑/↓」で明るさの調整ができる\nバックライトをつけておくとすぐにバッテリーがなくなるらしいので off にした\nKeymap Kinesis ADV360 Pro Keymap Editor で設定できる．\nWindows キーはあまりつかわないので ALT を配置 代わりに Caps を Windwos キーにした PgUp を ESC に，PgDn を 「CTRL + PG_DN」 にした 「CTRL + PG_DN」 で IME の切り替えをしているので 「LC」を選ぶと，LCTRL + PG_DN を選択できる ① と ② は迷い中 ③ と ④ に PG_UP と PG_DN を配置 キーキャップの数字とファンクションキーがずれていて迷うので数字と同じになるようにひとつずらした F12 と F13 の位置がひどいことになった バッテリー バックライトをオフにしていると 数ヶ月はもつらしい 「Mod + ④」で充電レベルを確認できる Green: 80% 以上 Yellow: 51% - 79% Orange: 21% - 50% Red: 20% 以下 高さ LOW/MEDIUM/HIGH の 3 段階に調整できる\n今は MEDIUM を使っている\nBluetooth の接続や遅延 特に問題なく使えている\n参考 Advantage 360 Professional (ZMK Bluetooth) Support Resources ","date":"2024-10-26T00:00:00+09:00","permalink":"https://miti-7.github.io/post/kinesis-advantage-360-pro-%E3%81%AE%E8%A8%AD%E5%AE%9A/","title":"Kinesis Advantage 360 Pro の設定"},{"content":"最小費用流問題(Minimum Cost Flow Problem) $N$ を頂点の集合，$A$ を辺の集合，$c_{ij}$ を辺 $(i, j)$ の単位流量あたりのコスト，$x_{ij}$ を辺 $(i, j)$ の流量，$b_i$ を頂点 i の需要/供給量，$l$ を辺の下限容量，$u$ を辺の上限容量としたとき，最小費用流問題（以下 MCFP）は以下のように定式化されます．\n1 つめの制約を流量保存則と呼び，第一項は頂点 $i$ から出る流量，第二項は頂点 $i$ に入る流量を表します． 2 つめの制約を容量制約と呼びます．\n$$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\sum_{(i, j) \\in A} c_{ij} x_{ij} \\\\ \u0026\\text{subject to} \u0026\u0026 \\sum_{j:(i, j) \\in A} x_{ij} - \\sum_{j:(j,i) \\in A} x_{ji} = b_i \u0026\u0026 \\forall i \\in N \\\\ \u0026 \u0026\u0026 l_{ij} \\le x_{ij} \\leq u_{ij} \u0026\u0026 \\forall (i, j) \\in A \\end{aligned} $$以下ではコスト，流量，需要/供給，下限容量，上限容量はすべて整数とします．また，$\\sum_{i \\in N} b_i = 0$，コストを非負，下限容量を $0$ とします．\n用語・定義 pseudoflow\n容量制約を満たす flow を pseudoflow と呼びます．流量保存則には違反していてもかまいません． 残余容量\n$r_{ij} = u_{ij} - x_{ij}$ を辺 (i, j) の残余容量と呼びます． imbalance\npseudoflow $\\bold x$ に対し，頂点 $i$ の imbalance を次のように定義します．第 2 項は $i$ に入ってくる流量の合計，第 3 項は $i$ から出ていく流量の合計です．\n$e(i) = b(i) + \\sum_{j:(j, i) \\in A} x_{ji} - \\sum_{j:(i,j) \\in A} x_{ij}$ reduced cost\n各頂点のポテンシャル $\\bold \\pi$ が与えられたとき，$c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ を辺 (i, j) の reduced cost と呼びます． Reduced Cost 最適性 最小費用流問題の実行可能な flow $\\bold x$ が最適であるための必要十分条件は，残余ネットワークのすべての辺 (i, j) に対して$c^{\\pi}_{ij} \\ge 0$ となるポテンシャル $\\bold \\pi$ が存在することです．\n最短路繰り返し法(Successive Shortest Path Algorithm) 最短路繰り返し法は，容量制約を満たすが流量保存則に違反する pseudoflow $\\bold x$ から開始します．\nアルゴリズムの各ステップでは reduced cost 最適性を維持しつつ，主問題の実行不能解 $\\bold x$ を実行可能解に近づけます．\n具体的には，残余ネットワーク上で $e(k) \\gt 0$ である頂点 $k$ から $e(l) \\lt 0$ である頂点 $l$ へ，最短路に沿って flow を流すことで実行可能性を高めていきます．\n実行可能解が得られたときアルゴリズムは終了します．\n最短路繰り返し法の流れは以下のようになります\n初期解の構築 $\\bold x = \\bold 0$，$\\bold \\pi = \\bold 0$ とする 実行可能解が得られるまで以下を繰り返す $e(k) \\gt 0$ である頂点 $k$ を選ぶ．各辺の reduced cost を距離とする残余ネットワーク上で，$k$ から各頂点への最短路を求める．$\\bold P$ を $k$ から各頂点への最短路，$\\bold d$ を最短距離とする ポテンシャルの更新 $\\bold \\pi^{\\prime} = \\bold \\pi - \\bold d$ flow の更新 $\\delta = min[e(k), min(r_{ij} : (i,j) \\in P)]$とし，$\\bold P$ に沿って辺の flow を $\\delta$ 増加する imbalance の更新 $e(k) = e(k) - \\delta$，$e(l) = e(l) + \\delta$ と更新する 次節からアルゴリズムの各ステップで常に reduced cost 最適性を維持することを確認していきます．\n初期解の構築 初期解が容量制約と reduced cost 最適性を満たすことを確認します．\n仮定より，下限容量は $0$ のため $\\bold x = \\bold 0$ は容量制約を満たします．\n$\\bold \\pi = \\bold 0$ のため $c_{ij}^{\\pi} = c_{ij}$ です．辺のコストはすべて非負を仮定しているため $c_{ij}^{\\pi} \\ge 0$ となり reduced cost 最適性を満たします．\nポテンシャルの更新 ある $\\bold x$ に対し $\\bold \\pi$ が reduced cost 最適性を満たしているとき，ポテンシャルを $\\bold \\pi^{\\prime} = \\bold \\pi - \\bold d$ と更新しても reduced cost 最適性を満たすことを示します1．\n$\\bold d$ は reduced cost を距離とした残余ネットワーク上での頂点 $k$ から各頂点への最短距離であるため，各辺 (i, j) は $d(j) \\le d(i) + c_{ij}^{\\pi}$ を満たします．\n上の式に $c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ を代入します．\n$d(j) \\le d(i) + c_{ij} - \\pi(i) + \\pi(j)$\n$d(j)$を移項し，頂点ごとにまとめます．\n$c_{ij} - (\\pi(i) - d(i)) + (\\pi(j) - d(j)) \\ge 0$\nポテンシャルの更新の仕方から以下が成り立ちます．\n$c_{ij} - \\pi^{\\prime}(i) + \\pi^{\\prime}(j) = c^{\\pi_{ij}^{\\prime}} \\ge 0$\nよって，ポテンシャルを $\\bold \\pi^{\\prime} = \\bold \\pi - \\bold d$ と更新しても reduced cost 最適性を満たすことがわかりました．\nflow の更新 最短路に沿って flow を更新したとき reduced cost 最適性を満たすことを確認します．\nまず，ポテンシャルを $\\bold \\pi^{\\prime} = \\bold \\pi - \\bold d$ と更新したとき，頂点 $k$ から各頂点への最短路の辺の reduced cost が $0$ となることを確認します．\n頂点 $k$ から頂点 $l$ の最短路を考えます．最短路であるため，この経路の各辺は $d(j) = d(i) + c_{ij}^{\\pi}$ を満たします．\n上の式に $c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ を代入します．\n$d(j) = d(i) + c_{ij} - \\pi(i) + \\pi(j)$\n$d(j)$ を移項し，頂点ごとにまとめます．\n$c_{ij} - (\\pi(i) - d(i)) + (\\pi(j) - d(j)) = 0$\nポテンシャルの更新の仕方から以下が成り立ちます．\n$c_{ij} - \\pi^{\\prime}(i) + \\pi^{\\prime}(j) = c^{\\pi_{ij}^{\\prime}} = 0$\nよって，頂点 $k$ から各頂点への最短路の辺の reduced cost は $0$ となることがわかりました．\n次に，flow を更新したとき reduced cost 最適性を満たすことを確認します．\n$\\delta = min[e(s), min(r_{ij} : (i,j) \\in P)]$ とし，最短路に沿って辺の flow を更新します．\n$\\delta$ 選び方から，このように flow を更新しても容量制約を満たします．また，reduced cost が $0$ であるため，辺に flow を流すことで残余ネットワーク上に逆辺が生じたとしても reduced cost 最適性には違反しません．\nよって，最短路に沿って flow を更新したとき reduced cost 最適性を満たすことがわかりました．\n計算量 $U$ を最大の供給量，$C$ をコストの最大値とします．\nアルゴリズムは各イテレーションで最短路問題を解き，供給量は厳密に減少します． よって，$nU$ 回のイテレーションでアルゴリズムは終了します．最短路問題に 2 分ヒープを使った dijkstra 法を使うとすると $O((m + n) \\log n)$ となります．\nよって，全体で $O(nU (m + n) \\log n)$ となります．\n補足：ポテンシャルの更新の改善 上記のアルゴリズムの説明では頂点 $k$ からすべての頂点に対する最短路を求めましたが，$e(l) \\lt 0$ のような頂点を見つけたとき探索を終了することができます．\ndijkstra 法で最短距離を求めているとします．最短距離が確定した頂点を permanently labeled node，まだ確定していない頂点を temporarily labeled node と呼びます．\nこのとき，ポテンシャルは以下のように更新することができます．\n$$ \\pi^{\\prime} = \\left\\{ \\begin{array}{ll} \\pi_{i} - d_{i} \u0026 \\text{node i is permanently labeled}\\\\ \\pi_{i} - d_{l} \u0026 \\text{node i is temporarily labeled} \\end{array} \\right. $$ 証明 $S$ を permanently labeled node の集合，$\\bar{S}$ を temporarily labeled node の集合とします． 頂点 $i$ と頂点 $j$ が $S$ と $T$ のどちらに属するかの 4 つ場合について，ポテンシャルが $\\boldd \\pi$ から $\\bold \\pi^{\\prime}$ に変更されたときを考えます． 1. $i \\in S, j \\in S$ の場合 「ポテンシャルの更新」の節と同じです．\n2. $i \\in S, j \\in \\bar{S}$ の場合 $c^{\\pi^{\\prime}} = c_{ij}^{\\pi} + d(i) - d(l)$ と更新されます．\n頂点 $j$ は最短距離と確定していないため，$d(l) \\le d(j)$ です．\nまた，頂点 $i$ は最短距離と確定しているため，dijkstra 法のアルゴリズムから $d(j) \\le d(i) + c_{ij}^{\\pi}$ が成り立ちます．\nよって，$d(l) \\le d(i) + c_{ij}^{\\pi}$ であるため $c_{ij}^{\\pi^{\\prime}} \\ge 0$ を満たします．\n3. $i \\in \\bar{S}, j \\in S$ の場合 $c^{\\pi^{\\prime}} = c_{ij}^{\\pi} + d(l) - d(j)$ と更新されます．\n頂点 $j$ は最短距離と確定しているため，$d(j) \\le d(l)$ です．\nよって，$c_{ij}^{\\pi^{\\prime}} \\ge 0$ を満たします．\n4. $i \\in \\bar{S}, j \\in \\bar{S}$ の場合 $c^{\\pi^{\\prime}} = c_{ij}^{\\pi} + d(l) - d(l)$ と更新されます．\nよって，$c_{ij}^{\\pi} \\ge 0$ を満たします．\nまた，すべてのポテンシャルに定数を加算しても reduced cost 最適性に影響はないため，全体に $d(l)$ を加算することで以下のように更新することもできます．\n$$ \\pi^{\\prime} = \\left\\{ \\begin{array}{ll} \\pi_{i} - d_{i} + d_{l} \u0026 \\text{node i is permanently labeled}\\\\ \\pi_{i} \u0026 \\text{node i is temporarily labeled} \\end{array} \\right. $$参考 Network Flows: Pearson New International Edition すべての頂点の距離が定まることを仮定しています．\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-10-21T00:00:00+09:00","permalink":"https://miti-7.github.io/post/%E6%9C%80%E5%B0%8F%E8%B2%BB%E7%94%A8%E6%B5%81%E5%95%8F%E9%A1%8C%E3%81%AE%E6%9C%80%E7%9F%AD%E8%B7%AF%E7%B9%B0%E3%82%8A%E8%BF%94%E3%81%97%E6%B3%95/","title":"最小費用流問題の最短路繰り返し法"},{"content":"最短路問題 有向グラフが与えられたとき，始点 s から各頂点への最短路を求める問題を単一始点最短路問題といいます．以下では，頂点数を $n$，辺数を $m$，各辺 (u, v) のコストを $c_{uv}$ で表します．また，グラフは強連結を仮定します．\n最短路問題の最適性条件 頂点集合を $N$，辺集合を $A$，辺 (u, v) のコストを $c_{uv}$ とします．始点 s から各頂点 v への有向パスの距離の上界を $d(v)$ で表し，これを距離ラベルと呼びます．特に，$d(s) = 0$ です．各頂点 $v \\in N$ について，$d(v)$ が始点 s から頂点 v の最短路の長さであるための必要十分条件は以下が成り立つことです．\n$$ \\begin{equation} d(v) \\le d(u) + c_{uv} \\quad \\forall (u, v) \\in A \\end{equation} $$不等式 (1) は，各辺 $(u, v) \\in A$ について，頂点 v への距離は頂点 u への距離 + $c_{uv}$ 以下であることを表しています．\n証明 まず，必要条件であることを示します．\n対偶をとり，$d(v) \\gt d(u) + c_{uv}$ ならば，距離ラベルが最短路の長さではないことを示します．\n$d(v) \\gt d(u) + c_{uv}$ であるような辺があれば，頂点 u を経由することで頂点 v への距離を改善することができます．\nしたがって，距離ラベル $d$ は最短路の長さではありません．\n次に，十分条件であることを示します．\n頂点 s から頂点 v への任意の有向パスが $s = i_1 \\rightarrow i_2 \\rightarrow \u0026hellip; \\rightarrow i_{k-1} \\rightarrow i_k = v$ であったとします．\n不等式 (1) から以下の式がそれぞれ成り立ちます．\n$$ \\begin{aligned} d(v) =\\; \u0026 d(i_k) \u0026\u0026 \\le\\; d(i_{k - 1}) \u0026\u0026 +\\; c_{i_{k - 1}i_{k}}, \\\\ \u0026 d(i_{k - 1}) \u0026\u0026 \\le\\; d(i_{k - 2}) \u0026\u0026 +\\; c_{i_{k - 2} i_{k - 1}}, \\\\ \u0026 \\vdots \\\\ \u0026 d(i_{2}) \u0026\u0026 \\le\\; d(i_{1}) \u0026\u0026 +\\; c_{i_{1}i_{2}} = c_{i_{1}i_{2}}. \\end{aligned} $$式をそれぞれ代入すると\n$$ d(v) = d(i_{k}) \\le c_{i_{k-1}i_{k}} + c_{i_{k-2}i_{k-1}} + \\dots + c_{i_{1}i_{2}} = \\sum_{(u, v) \\in P} c_{uv} $$となり，$d(v)$ は，始点 s から頂点 v への任意の有向パスのコストの合計の下界になります． $d(v)$ は始点 s から頂点 v への任意の有向パスの下界かつ上界なので，距離ラベル $d(v)$ は最短路の長さです．\n以上のことから，「各頂点 $v \\in N$ について距離ラベル $d(v)$ が最短路の長さである」の必要十分条件は，「各辺 $(u, v) \\in A$ について $d(v) \\le d(u) + c_{uv}$ を満たす」であることがわかりました．\nreduced arc length の性質 ある距離ラベル $d$ に対し，$c_{uv}^{d} = c_{uv} + d(u) - d(v)$ を reduced arc length と呼びます．reduced arc length には次の性質があります．\n任意の閉路 $W$ について，$\\sum_{(u, v) \\in W} c_{uv}^{d} = \\sum_{(u, v) \\in W} c_{uv}$ 頂点 k から頂点 l への任意の有向パス $P$ について，$\\sum_{(u, v) \\in P} c_{uv}^{d} = \\sum_{(u, v) \\in P} c_{uv} + d(k) - d(l)$ 距離ラベル $d$ が最適ならば，すべての辺 (u, v) について $c_{uv}^{d} \\ge 0$ が成り立つ 性質 1 の証明 $$ \\begin{aligned} \\sum_{(u, v) \\in W} c_{uv}^{d} \u0026= \\sum_{(u, v) \\in W} (c_{uv} + d(u) - d(v)) \\\\ \u0026= \\sum_{(u, v) \\in W} c_{uv} + \\sum_{(u, v) \\in W} (d(u) - d(v)) \\\\ \u0026= \\sum_{(u, v) \\in W} c_{uv} \\\\ \\end{aligned} $$任意の有向閉路 $W$ において，頂点 u は $+d(u)$としてちょうど 1 回，$-d(u)$ としてちょうど 1 回出現するため，$\\sum_{(u, v) \\in W} (d(u) - d(v)) = 0$ が成り立ちます．\n性質 2 の証明 $$ \\begin{aligned} \\sum_{(u, v) \\in P} c_{uv}^{d} \u0026= \\sum_{(u, v) \\in P} (c_{uv} + d(u) - d(v)) \\\\ \u0026= \\sum_{(u, v) \\in P} c_{uv} + \\sum_{(u, v) \\in P} (d(u) - d(v)) \\\\ \u0026= \\sum_{(u, v) \\in P} c_{uv} + d(k) - d(l) \\\\ \\end{aligned} $$頂点 k と頂点 l 以外の頂点は，$+d(u)$ としてちょうど 1 回，$-d(u)$ としてちょうど 1 回出現するため互いに打ち消し合います．\n頂点 k は $+d(k)$ として，頂点 $l$ は $-d(l)$ としてちょうど 1 回出現します．\n性質 3 の証明 最適性条件から直ちに言えます 次節からは，reduced arc length の性質を使ったアルゴリズムと問題を見ていきます．\nJohnson\u0026rsquo;s algorithm 任意の 2 頂点の組 (u, v) に対して頂点 u から頂点 v の最短路を求める問題を全点対最短路問題と呼びます．\nJohnson\u0026rsquo;s algorithm は全点対最短路問題を解くアルゴリズムです．\n頂点数が $n$ のとき，単一始点最短路問題を n 回解くことによって全点対最短路を求めることができます．\nただし，グラフにコストが負の辺があると，単一始点最路問題を解くのに Dijkstra 法を使うことができません．そこで，グラフのコストを reduced arc length に変換したグラフ上で最短路を求めることにします．reduced arc length の性質 3 から，最適距離ラベル $d$ に対する reduced arc length のコストはすべて 0 以上であるため Dijkstra 法を使うことができます．\n変換したグラフ上で最短距離を求めたあと，性質 2 を使って元のグラフの距離に変換します．\n最適距離ラベルは Bellman–Ford 法を使い求めることができます．負閉路が見つかった場合はアルゴリズムを終了します．\nDijkstra 法に二分ヒープを使うとき，Bellman–Ford 法に $O(nm)$，Dijkstra 法に $O((n + m) \\log n)$ かかるため，計算量は全体として $O(nm + n ((n + m) \\log n))$ となります．\n例として，AOJ - All Pairs Shortest Path を解きます．\n与えられるグラフは強連結ではないため，人工頂点 s を追加し，s から他のすべての頂点に重さ 0 の辺を張ります．この s を始点として Bellman-Ford 法を使うことで最適距離ラベルを求めることができます．\n実装では人工頂点を追加するのではなく， Bellman-Ford の初期解をすべて 0 とすることで対応しています．\n提出コード\nABC237 E - Skiing 問題概要\n$N$ 頂点，$M$ 辺の強連結の有向グラフと各頂点 u の高さ $H(u)$ が与えられる．$H(u) \\ge H(v)$ としたとき，頂点 u から頂点 v にはコスト $H(v) - H(u)$ の辺が，頂点 v から頂点 u にはコスト $2(H(u) - H(v))$ の辺が張られている．頂点 1 から各頂点への最短距離の中で最も小さいものを求めよ．\n負辺のあるグラフの最短路問題なので Bellman–Ford 法を使えば答えが求まりますが，Bellman–Ford 法の計算量は $O(nm)$ なので TLE になってしまいます． そこで，グラフのコストを reduced arc length に変換したグラフ上で最短路を求めることにします．\nまず，不等式 (1) を満たすような距離ラベルを考えます．\nある距離ラベル $d$ に対して，$H(u) \\ge H(v)$ のとき，$c_{uv}^{d}$ と $c_{vu}^{d}$ は以下のように表せます．\n$$ \\begin{aligned} c_{uv}^{d} \u0026= c_{uv} + d(u) - d(v) = H(v) - H(u) + d(u) - d(v) \\\\ c_{vu}^{d} \u0026= c_{vu} + d(v) - d(u) = 2(H(u)- H(v)) + d(v) - d(u) \\\\ \\end{aligned} $$u と v についてまとめて式を整理します．\n$$ \\begin{aligned} c_{uv}^{d} \u0026= (H(v) - d(v)) - (H(u) - d(u)) \\\\ c_{vu}^{d} \u0026= (2H(u) - d(u)) - (2H(v) - d(v)) \\\\ \\end{aligned} $$$c_{uv}^{d} \\ge 0$ かつ $c_{vu}^{d} \\ge 0$ にしたいので，各頂点 u について $d(u) = H(u)$ とすると以下のようになります．\n$$ \\begin{aligned} c_{uv}^{d} \u0026= (H(v) - H(v)) - (H(u) - H(u)) = 0 \\\\ c_{vu}^{d} \u0026= (2H(u) - H(u)) - (2H(v) - H(v)) = H(u) - H(v)\\\\ \\end{aligned} $$以上のことから，次のように問題を言い換えることができます．\n$N$ 頂点，$M$ 辺の強連結の有向グラフと各頂点 u の高さ $H(u)$ が与えられる．$H(u) \\ge H(v)$ のとき，頂点 u から頂点 v にはコスト 0 の辺が，頂点 v から頂点 u にはコスト $H(u) - H(v)$ の辺が張られている．頂点 1 から各頂点への最短距離の中で最も小さいものを求めよ．\nすべての辺のコストは 0 以上なので Dijkstra 法で求めることができます．\n求まる値は変換したグラフ上での値なので，$distance[u] - H[0] + H[u]$ として元のグラフ上での値に戻します．\n提出コード\n参考 Network Flows: Pearson New International Edition Johnson\u0026rsquo;s algorithm E - Skiing 解説 ","date":"2024-09-17T00:00:00+09:00","permalink":"https://miti-7.github.io/post/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%95%8F%E9%A1%8C%E3%81%AE%E6%9C%80%E9%81%A9%E6%80%A7%E6%9D%A1%E4%BB%B6%E3%81%A8-reduced-arc-length/","title":"最短路問題の最適性条件と reduced arc length"},{"content":"hugo ではサーバーの実行中にファイルが変更されるとサイトを再構築し自動的にブラウザを更新してくれる機能があるのですが ，Frequently asked questions によると WSL で実行しているときはうまく動作しないことがあるらしいです．\nこのようなときは server を起動するときに，poll オプションを指定すると定期的にポーリングしてくれます．\n1 hugo server --poll \u0026#34;700ms\u0026#34; ","date":"2024-09-15T00:00:00+09:00","permalink":"https://miti-7.github.io/post/hugo-%E3%81%A7%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%A4%89%E6%9B%B4%E3%81%8C%E6%A4%9C%E5%87%BA%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%87%A6/","title":"HUGO でファイル変更が検出されないときの対処"},{"content":"最小費用流問題(Minimum Cost Flow Problem) $N$ を頂点の集合，$A$ を辺の集合，$c_{ij}$ を辺 $(i, j)$ の単位流量あたりのコスト，$x_{ij}$ を辺 $(i, j)$ の流量，$b_i$ を頂点 i の需要/供給量，$l$ を辺の下限容量，$u$ を辺の上限容量としたとき，最小費用流問題（以下 MCFP）は以下のように定式化されます．\n1 つめの制約を流量保存則と呼び，第一項は頂点 i から出る流量，第二項は頂点 i に入る流量を表します． 2 つめの制約を容量制約と呼びます．\n$$ \\begin{aligned} \u0026\\text{minimize} \u0026\u0026 \\sum_{(i, j) \\in A} c_{ij} x_{ij} \\\\ \u0026\\text{subject to} \u0026\u0026 \\sum_{j:(i, j) \\in A} x_{ij} - \\sum_{j:(j,i) \\in A} x_{ji} = b_i \u0026\u0026 \\forall i \\in N \\\\ \u0026 \u0026\u0026 l_{ij} \\le x_{ij} \\leq u_{ij} \u0026\u0026 \\forall (i, j) \\in A \\end{aligned} $$以下ではコスト，流量，需要/供給，下限容量，上限容量はすべて整数とします．また，$\\sum_{i \\in N} b_i = 0$ を仮定します．\nPrimal Network Simplex 法 primal network simplex 法は，ネットワーク構造を利用することで simplex 法を効率化させたアルゴリズムです．今回は primal network simplex 法で MCFP を解いていきます．\nMCFP が必ず 最適 spanning tree solution という解を持つことを利用し，spanning tree solution のみを探索することで効率的に最適解を見つけることができます1．\nprimal network simplex 法は，simplex 法の観点と負閉路除去法の観点から説明することができますが，今回は負閉路除去法の観点で説明します． 節 1 で spanning tree solution の定義をします．節 2 で spanning tree solution は spanning tree structure として表せることと，spanning tree structure が最適解となる条件について示します．節 3 で primal network simplex 法の流れについて説明し，節 4 から 節 8 でアルゴリズムの各段階の詳細について述べます．節 9 から節 11 で退化について説明します．\n1. spanning tree solution ある実行可能解 $x$ に対して， $l_{ij} \u0026lt; x_{ij} \u0026lt; u_{ij}$ を満たす辺を free arc，$x_{ij} = l_{ij}$ か $x_{ij} = u_{ij}$ を満たす辺を restricted arc と呼びます． 解 $x$ とそれに関連する全域木が以下の条件を満たすとき，spanning tree solution と呼びます．特に，$x$ が 最適解であるとき最適 spanning tree solution と呼びます．\n$x$ が実行可能解である 全域木に含まれない辺（non-tree arc）がすべて restricted arc である 具体例を示します．簡単のため，辺容量の下限はすべて 0 としコストは省略します．$b(0) = 2$，$b(3) = -2$ とします．\n下の図のグラフでは辺 (0, 1)，(2, 3) が free arc，辺 (0, 2)，(1, 2)，(1, 3) が restricted arc です．\n解 $x$ は流量保存則と容量制約を満たすため実行可能解です．全域木として，青色の辺 (0, 1)，(0, 2)，(2, 3) を選ぶ2と，non-tree arc は (1, 2) と (1, 3) となり，すべて restricted arc であるため spanning tree solution となります．\nまた，全域木として，青色の辺 (0, 1)，(1, 2)，(2, 3) を選んでも spanning tree solution となります． このように，1 つの実行可能解に複数の spanning tree solution が対応することがあります．\n2. spanning tree structure と最適性条件 spanning tree solution は辺集合を次の 3 つに分割します．\nT: 全域木の辺 L: non-tree arc のうち，flow が下限の辺 U: non-tree arc のうち，flow が上限の辺 この 3 つ組 (T, L, U) を spanning tree structure と呼びます．spanning tree structure は spanning tree solution から一意に構築されます．\n頂点 i のポテンシャルを $\\pi(i)$，辺 (i, j) の reduced cost を $c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ で表します．spanning tree structure が次の条件を満たすとき，spanning tree structure に対応する spanning tree solution は最適 spanning solution となります．このような，spanning tree structure を最適 spanning tree structure と呼びます．\n$$ \\begin{aligned} c^{\\pi}_{ij} = 0 \u0026\u0026 \\forall (i, j) \\in T \\\\ c^{\\pi}_{ij} \\ge 0 \u0026\u0026 \\forall (i, j) \\in L \\\\ c^{\\pi}_{ij} \\le 0 \u0026\u0026 \\forall (i, j) \\in U \\\\ \\end{aligned} $$全域木の根のポテンシャルを 0 と固定すると $T$ に属する辺 (i, j) が $c^{\\pi}_{ij} = 0$ を満たすように各頂点のポテンシャル $\\pi$ を定めることができます．このとき，$-\\pi(i)$ は根から頂点 i への木のパスの長さとみなすことができます． 具体例として，下の図の全域木について各頂点のポテンシャルを求めていきます．頂点 0 を根とします．\n頂点 1 のポテンシャルを求めます． 辺 (i, j) の reduced cost は $c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ です．全域木の辺の reduced cost は 0，辺 (0, 1) のコストは 1，頂点 0 のポテンシャルは 0 であることから，$0 = 1 - 0 + \\pi(1)$ となり，$\\pi(1) = -1$と求められます．\n頂点 2 のポテンシャルを求めます． 辺 (2, 1) のコストは 5 ，頂点 1 のポテンシャルは -1 なので，$0 = 5 - \\pi(2) + (-1)$ となり，$\\pi(2) = 4$ と求められます．\n同様の計算を行うことで，全頂点のポテンシャルを計算することができます．\n全頂点のポテンシャルを求めると，$L$ と $U$ に属する辺の reduced cost を計算することができます．すべての辺が最適性条件を満たすならば，最適 spanning tree structure と判定できます．\n3. Network Simplex 法のアルゴリズムの流れ spanning tree structure が与えられたとき，全域木の reduced cost が 0 となるように各頂点のポテンシャルを計算し，各辺の reduced cost を求めることで最適 spanning structure かどうか判定することができました． 最適 spanning tree structure でない場合， $L$ に属する $c_{ij}^{\\pi} \\lt 0$ である辺か，$U$ に属する $c_{ij}^{\\pi} \\gt 0$ である辺が 1 つ以上存在することになります． これらの辺を $T$ に追加したときを考えます．\n$L$ に属する $c^{\\pi}_{ij} \\lt 0$ である辺を $T$ に追加 $L$ に属する $c_{ij}^{\\pi} \\lt 0$ である辺 (i, j) を $T$ に追加したとします．\nこのとき，根から i，i から j，j から根をたどるパスの flow を 1 増加すると，目的関数値は $c^{\\pi}_{ij}$ 増加します．\n具体例を見てみます．下の図の全域木にコスト -8 の辺 (2, 4) を追加したとします．この辺の reduced cost は $-8 - 4 + (-3) = -15$ です．\n辺 (0, 1)，(2, 1)，(2, 4)，(3, 4)，(3, 0) の順に flow を 1 単位流すと，全体のコストの合計は，1 + (-5) + (-8) + (-5) + 2 = -15 となり，目的関数値が 15 減少する（-15 増加する）ことがわかります3．\n$U$ に属する $c^{\\pi}_{ij} \\gt 0$ である辺を $T$ に追加 $U$ に属する $c_{ij}^{\\pi} \\gt 0$ である辺 (i, j) を $T$ に追加したとします．\nこのとき，根から j， j から i，i から根をたどるパスの flow を 1 増加すると，目的関数値は $c^{\\pi}_{ij}$ 減少します．\n下の図の全域木にコスト -5 の辺 (6, 4) を追加したとします．この辺の reduced cost は $(-5) - (-11) + (-3) = 3$ です．\n辺 (3, 0)，(3, 4)，(6, 4)，(5, 6)，(3, 5)，(3, 0) の順に flow を 1 単位流すと，全体のコストの合計は，-2 + 5 + (-(-5)) + (-7) + (-6) + 2 = -3 となり，目的関数値が 3 減少することがわかります．\nまた，辺 (0, 3) に対し，頂点 0 から 頂点 3 に flow を流し，頂点 3 から頂点 0 に flow を流すと flow は打ち消し合うため，追加した辺によって生じる閉路のみを考慮すればいいこともわかります．\n以上のことから，spanning tree structure が最適でないとき，最適性条件に違反する辺を全域木に追加したことによって生じる閉路の flow を更新することで目的関数値を減少できることがわかりました．\n閉路の flow を限界まで増加させると，1 本以上の辺の flow が下限容量か上限容量に達するため，その辺を取り除くことによって新しい spanning tree solution を生成することができます．\nprimal network simplex 法は これらの処理を最適性条件を満たすまで繰り返すことで最適解を求めます．\nprimal network simplex 法の流れは以下のようになります\n初期 spanning tree structure を構築する spanning tree structure が最適性条件を満たさない間，以下を繰り返す 最適性条件に違反する辺を $U$ か $L$ から選び，全域木に追加する 閉路の flow を更新する flow が下限容量か上限容量に達した辺を閉路から 1 つ取り除き新しく全域木を作成する 次節からアルゴリズムの各段階の詳細について説明していきます．\n4. 初期 spanning tree structre の構築 初期 spanning tree structre (T, L, U) を構築します．\nまず，人工頂点 $s$ を作り，$s$ と既存の各頂点 $u$ の間に以下のように辺をはります．\n$b(u) \\ge 0$ の場合，流量 $b(u)$ の辺 $(u, s)$ を加える $b(u) \\lt 0$ の場合，流量 $-b(u)$ の辺 $(s, u)$ を加える いずれの人工辺も容量とコストは十分大きい値とします．人工辺は $T$ に，もとからある辺は $L$ に，$U$ は空とします.\nこのように作られた spanning tree structure は実行可能解です．今後はこの拡張された network 上で問題を解いていきます．人工辺のコストは十分大きいため最適解が得られたとき人工辺に flow は流れていません．\n例として下のグラフの初期 spanning tree structure を構築します．\n$b(0) = 2$，$b(3) = -2$，他の頂点の需要/供給は 0 とします．また，すべての辺の下限容量は 0 とします4．\nまず，人工頂点として，$s$ を追加します．\n$b(u) \\ge 0$ である頂点 0, 1, 2 から s に向けて辺を追加します．$b(0) = 2$ であるため，辺 (0, s)の flow は 2 とします．\ns から $b(u) \\lt 0$ である頂点 3 に向けて辺を追加します．$b(3) = -2$ であるため，辺 (s, 3)の flow は 2 とします．\n初期 spanning tree structure は以下のようになります．\n$T$ に属する辺：(0, s)，(1, s)，(2, s)，(s, 3) $L$ に属する辺：(0, 1)，(0, 2)，(1, 2)，(1, 3)，(2, 3) $U$ に属する辺：なし 5. entring arc の選択 $T$ に追加する辺（entring arc）を $U$ か $L$ から選びます．\nこのとき，以下のような最適性条件を満たさない辺（eligible arc）を選びます．また，$|c^{\\pi}_{ij}|$ を violation と呼びます．\n$$ \\begin{aligned} c^{\\pi}_{ij} \\lt 0 \u0026\u0026 \\forall (i, j) \\in L \\\\ c^{\\pi}_{ij} \\gt 0 \u0026\u0026 \\forall (i, j) \\in U \\end{aligned} $$代表的な辺の選択方法は以下の 3 つです．\nBest eligible arc pivot rule(Dantzig\u0026rsquo;s pivot rule)\nviolation の最も大きい eligible arc を entring arc とする 1 flow 単位の改善が最も大きいため，イテレーションの回数は少なくなる すべての non-tree arc を調べる必要があるため，1 回のイテレーションのコストが大きい First eligible arc pivot rule\n最初に見つけた eligible arc を entring arc とする．次のイテレーションでは，前回選択した辺の次から探索を開始する．最後の辺まで探索をしたら先頭に戻る 1 回のイテレーションのコストが小さい 1 flow 単位の改善が小さくなるので，イテレーションの回数が多くなる Block search pivot rule\n辺をブロックに分割し，ブロックの中で violation の最も大きい eligible arc を entring arc とする．ブロック内で見つからなかった場合，次のブロックを探索する すべての辺を同じブロックにしたとき，Best eligible arc pivot rule と同じ挙動になる すべての辺を違うブロックにしたとき，First eligible arc pivot rule と同じ挙動になる 6. flow の更新 全域木に辺を追加すると閉路 $W$ がちょうど 1 つできます．この閉路の flow を 1 単位増加するごとに，MCFP の目的関数値は $|c^{\\pi}_{ij}|$ 減少するため，$W$ の flow を容量制約を満たす限界まで増加します．\n閉路 $W$ の向きを次のように定めます．\n$(k, l) \\in L$ のとき，辺 (k, l) と同じ方向 $(k, l) \\in U$ のとき，辺 (k, l) と逆方向 閉路 $W$ の順辺の集合を $\\bar W$，逆辺の集合を $\\underbar W$ で表したとき，$W$ の各辺の flow の増加できる量は以下のようになります．\n$$ \\delta_{ij} = \\left\\{ \\begin{array}{ll} u_{ij} - x_{ij} \u0026 (i, j) \\in \\bar{W}\\\\ x_{ij} - l_{ij} \u0026 (i, j) \\in \\underbar{W} \\end{array} \\right. $$$\\delta = min \\lbrace \\delta_{ij} : (i, j) \\in W \\rbrace$ とし，$W$ の各辺の flow を以下のように更新します．\n$$ x_{ij} = \\left\\{ \\begin{array}{ll} x_{ij} + \\delta \u0026 (i, j) \\in \\bar{W}\\\\ x_{ij} - \\delta \u0026 (i, j) \\in \\underbar{W} \\end{array} \\right. $$具体例を見ます．すべての辺の下限は 0 とします．\n$U$ に属する辺 (6, 4) を $T$ に追加すると，辺 (6, 4)，(5, 6)，(3, 5)，(3, 4) からなる閉路ができます．\n辺 (6, 4) は $U$ に属するので，(6, 4) と逆方向である反時計回りを $W$ の向きとします．$\\bar W$ に属する辺は，(3, 4)，$\\underbar W$ に属する辺は，(6, 4)，(5, 6)，(3, 5) です．\n各辺の $\\delta_{ij}$ と $\\delta$ は以下の通りです．\n$\\delta_{64} = 6 - 0 = 6$ $\\delta_{56} = 2 - 0 = 2$ $\\delta_{35} = 4 - 0 = 4$ $\\delta_{34} = 3 - 1 = 2$ $\\delta = min \\lbrace 6, 2, 4, 2 \\rbrace = 2$ 閉路 $W$ の flow を 2 増加すると以下のようになります．\n別の例をみます． 辺 (3, 4) の flow が 3 のとき，各辺の $\\delta_{ij}$は以下のようになります．\n$\\delta_{64} = 6 - 0 = 6$ $\\delta_{56} = 2 - 0 = 2$ $\\delta_{35} = 4 - 0 = 4$ $\\delta_{34} = 3 - 3 = 0$ $\\delta = min \\lbrace 6, 2, 4, 0 \\rbrace = 0$ このように全域木に $x_{ij} = l_{ij}$ や $x_{ij} = u_{ij}$ の辺があると flow が更新できないことがあります．\n7. leaving arc の選択 閉路の flow を限界まで増加したとき 1 本以上の辺が $\\delta = \\delta_{ij}$ となります．この辺を blocking arc と呼びます．\nblocking arc を取り除く辺（leaving arc）として選びます（複数ある場合は任意の辺を選びます）．\n辺 (i, j) が $x_{ij}$ = $l_{ij}$ になったときは $L$ に，$x_{ij} = u_{ij}$ になったときは $U$ に入ります．\n閉路 $W$ の flow を更新した結果，辺 (5, 6) の flow が下限容量に，辺 (3, 4) の flow が上限容量になった場合を考えます．\n辺 (5, 6) と辺 (3, 4) のどちらかを取り除くことができます．辺 (5, 6) を取り除き $L$ に追加すると下の全域木 $T$ が得られます．\n8. ポテンシャルの更新 辺 (p, q) を削除したとき，木は 2 つの部分木に分割されます．根がある方の部分木を $T_1$，ない方の部分木を $T_2$ とします．\n木の根のポテンシャルを 0 に固定し， 辺の reduced cost が 0 になるようにポテンシャルを算出していたことを考えると，$T_1$ に含まれる頂点のポテンシャルは変化せず，$T_2$ に含まれる頂点のポテンシャルのみ変化することがわかります．\n全域木に辺 (k, l) が追加され，頂点 k が $T_1$ に，頂点 l が $T_2$ に含まれる場合を考えます．\n$T_2$ は頂点 q を根とする部分木から頂点 l を根とする部分木に変化するため，$T_2$ に属する頂点のポテンシャルを更新する必要があります．\n木のすべての頂点のポテンシャルに定数を加算しても reduced cost は保たれるため，新しい $\\pi(l)$ と現在の $\\pi(l)$ の差分 $d$ が求められれば，$T_2$ に属するすべての頂点に $d$ を加算することでポテンシャルを正しい値に更新できます．\n頂点 k のポテンシャルは変化しないことから，頂点 l の新しいポテンシャル $\\pi^{\\prime}(l)$ は $0 - c_{kl} + \\pi(k)$ となります．\nよって，頂点 l の新しいポテンシャルとの現在のポテンシャルの差は $\\pi^{\\prime}(l) - \\pi(l) = 0 - c_{kl} + \\pi(k) - \\pi(l) = -(c_{kl} - \\pi(k) + \\pi(l))$ となり，これは $-c_{kl}^{\\pi}$ です．\n以上のことから，$T_2$ に属するすべての頂点に $-c_{kl}^{\\pi}$ を加算することでポテンシャルを正しい値に更新できることがわかりました．\n頂点 l が $T_1$ に，頂点 k が $T_2$ に含まれる場合も同様の議論により，$c_{kl}^{\\pi}$ 増加することが示せます．\nまとめると，辺 (k, l)を追加したとき $T_2$ に含まれる頂点のポテンシャルは以下のように更新されます．\n頂点 k が $T_1$ に，頂点 l が $T_2$ に含まれる場合 $T_2$ に含まれる頂点のポテンシャルは $-c^{\\pi}_{kl}$ 増加 頂点 l が $T_1$ に，頂点 k が $T_2$ に含まれる場合 $T_2$ に含まれる頂点のポテンシャルは $c^{\\pi}_{kl}$ 増加 9. Strongly Feasible Spanning Tree primal network simplex 法が有限回で終了するのかを考えます．\nアルゴリズムの各イテレーションでは，全域木に辺を追加するこことで閉路を作り，この閉路の flow を更新することで目的関数値を減少させます．\n目的関数値は flow 1 単位あたり $|c^{\\pi}_{ij}|$ 減少するため，常に正の量の flow を流せるならアルゴリズムは有限回で終了します．\nしかし，節 6 の最後の例のように閉路に restricted arc があると flow が増加できないイテレーションが発生することがあります．このイテレーションを degenerate iteration といいます．\n実は primal network simplex 法は entring arc と leaving arc を任意に選ぶと degenerate iteration が無限に発生しアルゴリズムが有限回で終了しないことがあります．\nそこで，strongly feasible spanning tree という概念を導入します．\n常に strongly feasible spanning tree を維持することによって，アルゴリズムが有限回で終了することが保証できます．\nstrongly feasible spanning tree 次の条件を満たす spanning tree を strongly feasible spanning tree と呼びます．\n任意の頂点から正の量の flow を容量制約に違反することなく木に沿って根に送ることができる 下の図は strongly feasible spanning tree の例です．\nすべての頂点から頂点 0 に向かって 1 以上の flow を送ることができます．\nstrongly feasible spanning tree は flow が下限の辺のは根に向いていて，flow が上限の辺は根と反対を向いている全域木とみなすこともできます．\n下の図は strongly feasible spanning tree ではない例です．\n辺 (2, 1) の flow は上限容量であるため，頂点 2 から根に flow を送ることはできません．また，辺 (3, 4) の flow は下限容量であるため，頂点 4 から根に flow を送ることはできません．\n節 4 の「初期 spanning tree structure の構築」は strongly feasible spanning tree を構築します．次の節で leaving arc をどのように選べば strongly feasible spanning tree を維持できるのか見ていきます．\n10. Strongly Feasible Spanning Tree を保つ leaving arc の選び方 辺 (k, l) を entring arc とします．頂点 k と l の最小共通祖先を頂点 w とします．\nこのとき閉路 $W$ に沿って，頂点 w から開始して最後に見つけた blocking arc を leaving arc とすると，spanning tree は strongly feasible を維持できます．\n具体例をみます．\n$L$ に属する辺 (k, l) が追加され閉路 $W$ が生成されたとします．閉路の向きは辺 (k, l) と同じ向きです．\nこの閉路には flow を流すことができず，辺 (w, 1) と辺 (p, q) が blocking arc になります．\n頂点 w から閉路の向きに沿って探索し，最後に見つかる blocking arc は辺 (p, q) であるため，この辺を leaving arc とします．\nstrongly feasible spanning tree から上記の方法で leaving arc を選んだとき，strongly feasible spanning tree が維持されることを示します．pivot 操作の直前は strongly feasible spanning tree であるという前提を利用します．\n頂点 w から頂点 q のパスを $W_1$，頂点 p から頂点 w のパスを $W_2$ とします．\n「$W_1$」，「$W_2$」，「閉路以外の頂点」の 3 つについて，「任意の頂点から正の量の flow を容量制約に違反することなく木に沿って根に送ることができる」という条件を満たすか確認します．\n$W_1$ 内の頂点\n直前が non-degenerate pivot5 の場合 $\\delta \\gt 0$ であるため，頂点 w から$W_1$ 内の頂点に flow が送られている．$W_1$ の各頂点からは頂点 w まで $\\delta$ の flow を押し戻すことができるため条件を満たす 直前が degenerate pivot6 の場合 前提から，pivot の直前では頂点 l から頂点 w のパスで flow を送れていたため，このパス内に blocking arc は存在しない．よって $W_1$ は頂点 w と頂点 k の間にある $\\delta = 0$ であり，頂点 w から頂点 k のどの辺の flow にも変化はないため条件を満たす $W_2$ 内の頂点\nleaving arc の選び方を考えると，$W_2$ 内に blocking arc はないため条件を満たす $W$ 以外の頂点\n頂点 u から根へのパスに閉路 $W$ が含まれないとき 前提から，閉路以外の flow に変化はないため，条件を満たす 頂点 u から根へのパスに閉路 $W$ が含まれるとき u から閉路までのパスは，flow に変化がないため条件を満たす．閉路に到達したとき閉路から根まで条件を満たすので全体として条件を満たす 以上のことから，leaving arc に $W$ に沿って最後に見つけた blocking arc を選ぶことで，常に strongly feasible spanning tree を維持できることがわかりました．\n11. アルゴリズムが有限回で終了することの証明 2 つの non-degenerate pivot の間の連続する degenerate pivot が有限回であることを示します．\ndegenerate pivot が発生したとき，ノードのポテンシャルが単調減少することを示します．$n$ を頂点の数，$C$ をコストの絶対値の最大値としたとき，ノードのポテンシャルの下界は $-nC$ であるため連続する degenerate pivot は有限回で終了します．\nentring arc (k, l) が $L$ に属していた場合\n辺 (k, l) は $L$ に属し，最適性条件に違反するため，reduced cost は $c^{\\pi}_{kl} \\lt 0$ です． 全域木は常に strongly feasible spanning tree を維持していることを考えると，degenerate pivot の場合は頂点 l から頂点 w の間に blocking arc は存在しないため，新しく作成される木は頂点 l に 頂点 k がぶら下がる形になります． 頂点 k を根とする部分木のポテンシャルは $c^{\\pi}_{kl} \\lt 0$ 増加するため，ノードのポテンシャルは単調減少します entring arc (k, l) が $U$ に属していた場合\n辺 (k, l) は $U$ に属し，最適性条件に違反するため，reduced cost は $c^{\\pi}_{kl} \\gt 0$ です． 新しく作成される木は頂点 k に 頂点 l がぶら下がる形になります． 頂点 l を根とする部分木のポテンシャルは $c^{\\pi}_{kl} \\gt 0$ 減少するため，ノードのポテンシャルは単調減少します 以上のことから 2 つの non-degenerate pivot の間の連続する degenerate pivot が有限回であることがわかりました． non-degenerate pivot は目的関数値を厳密に減少させるため，アルゴリズムは有限回で終了します．\n補足 1. 最適 spanning tree solution が必ず存在することについて cycle free solution free arc のみからなる閉路を持たないような実行可能解 $x$ を cycle free solution といいます．\n下の図は cycle free solution の例です．辺の上に (流量，コスト) を示し，下限容量は 0，上限容量は無限とします．\n青色の辺 (0, 1)，(1, 3)，(3, 4) が free arc です．free arc のみからなる閉路がないため cycle free solution です．この解の目的関数値は $(2 \\times 0) + (2 \\times 1) + (2 \\times 0) = 2$ です．\n下の図は cycle free solution ではない例です．\n青色の辺 (0, 1)，(1, 2)，(1, 3)，(2, 4)，(3, 4) が free arc です．free arc のみからなる閉路があるため cycle free solution ではありません．この解の目的関数値は $(2 \\times 0) + (1 \\times 3) + (1 \\times 1) + (1 \\times -1) + (1 \\times 0) = 3$ です．\ncycle free solution でない解が与えられたとき，閉路の flow を操作することで，目的関数値が大きくならないように cycle free solution にすることができます．\nこの解の場合，時計回りに flow を 1 増加すると，辺 (2, 4)，(1, 2) の flow が 1 減り，辺(1, 3)，(3, 4) の flow が 1 増えます．結果，この解の目的関数値は $(2 \\times 0) + (0 \\times 3) + (2 \\times 1) + (0 \\times -1) + (2 \\times 0) = 2$ と 1 小さくなり，さらに cycle free solution になりました．\nこのように，cycle free でない解は閉路の flow を操作することで目的関数値が大きくならないように cycle free solution にできるため，MCFP に最適解があるとき，常に同じ目的関数値である cycle free solution を持つことがわかります．\ncycle free solution から spanning tree solution を求める cycle free solution は辺を適切に選ぶことで spanning tree solution を求めるとができます．\n下の図では，青色の辺(0, 1)，(1, 2)，(1, 3)，(3, 4) を全域木として選んでいます．\n以上のことから，MCFP に最適解があるとき，常に同じ目的関数値である最適 spanning tree solution を持つことがわかりました．\n補足 2. Spanning Tree Structure の最適性条件 spanning tree structure が次の条件を満たすとき，spanning tree structure に対応する spanning tree solution は最適 spanning solution となることを示します．\n$$ \\begin{aligned} c^{\\pi}_{ij} = 0 \u0026\u0026 \\forall (i, j) \\in T \\\\ c^{\\pi}_{ij} \\ge 0 \u0026\u0026 \\forall (i, j) \\in L \\\\ c^{\\pi}_{ij} \\le 0 \u0026\u0026 \\forall (i, j) \\in U \\\\ \\end{aligned} $$まず，$\\sum_{(i, j) \\in A} c_{ij} x_{ij}$ を最小化することは $\\sum_{(i, j) \\in A} c_{ij}^{\\pi} x_{ij}$ を最小化することと等しいことを示します．\n$z(\\pi) = \\sum_{(i, j) \\in A} c_{ij}^{\\pi} x_{ij}$ とします．$c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ なので，$z(0) = \\sum_{(i, j) \\in A} c_{ij} x_{ij}$ です．\n頂点 k のポテンシャルを $0$ から $\\pi(k)$ まで増加したとします．\n$c_{ij}^{\\pi} = c_{ij} - \\pi(i) + \\pi(j)$ なので，reduced cost は頂点 k から流出する flow 1 単位あたり $\\pi(k)$ 減少し，頂点 k に流入する flow 1 単位あたり $\\pi(k)$ 増加します．よって，全体の reduced cost は $ - \\pi(k) \\times k$ からの流出量 + $\\pi(k) \\times k$ への流入量だけ変化します．\nMCFP の制約条件から，各頂点 i の流出量と流入量の関係は $\\sum_{j:(i, j) \\in A} x_{ij} - \\sum_{j:(j,i) \\in A} x_{ji} = b_i$ です．\nよって，頂点 k のポテンシャルを $\\pi(k)$ 増加すると，目的関数値は $\\pi(k)b(k)$ 減少することになります．\nすべての頂点に同様のことがいえるので，$z(0) - z(\\pi) = \\sum_{i \\in N} \\pi(i)b(i) = \\pi b$ となります．\n$\\pi b$ は定数のため，$z(\\pi)$ を最小化する flow は $z(0)$ を最小化することがわかりました．\n次に，$x^{\\ast}$ を上の最適性条件を満たす (T, L, U) に対応する解としたとき，これが最適解であることを示します．\n最適性条件を満たすポテンシャルを $\\pi$ としたとき，$\\sum_{(i, j) \\in A} c_{ij}^{\\pi} x_{ij}$ の最小化を考えます．\n$\\sum_{(i, j) \\in A} c_{ij}^{\\pi} x_{ij}$ を最小化することは $\\sum_{(i, j) \\in L} c_{ij}^{\\pi} x_{ij} - \\sum_{(i, j) \\in U} |c_{ij}^{\\pi}| x_{ij}$ を最小化すること等しいです．\n$\\forall (i, j) \\in L$ に対して $x_{ij} \\ge x_{ij}^{\\ast} = l_{ij}$ であり，$\\forall (i, j) \\in U$ に対して $x_{ij} \\le x_{ij}^{\\ast} = u_{ij}$ であるため，$x^{\\ast}$ の目的関数値は $x$ の目的関数値以下となります．\n以上のことから，最適性条件を満たす spanning tree structure は最適解となることがわかりました．\n参考 Network Flows: Pearson New International Edition The network simplex algorithm IE 411: Graphs and Network Flows (Python) 正確には，実行可能領域に下界が存在するならば最適 spanning tree solution が少なくとも 1 つ存在します．\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n全域木の辺として restricted arc を選ぶこともできます\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n辺 (i, j) に対し頂点 j から頂点 i に flow を流すと，辺 (i, j) の flow を減らすことになります．例えば，辺 (2, 1) に対して頂点 1 から頂点 2 に flow を流すと，辺 (2, 1) の flow は 1 減り，コストは 5 下がります．\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n辺の lower が 0 でない場合，先に lower 分の flow を流しておきます．\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n$\\delta \\gt 0$ である pivot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n$\\delta = 0$ である pivot\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-11T00:00:00+09:00","image":"https://miti-7.github.io/post/%E6%9C%80%E5%B0%8F%E8%B2%BB%E7%94%A8%E6%B5%81%E5%95%8F%E9%A1%8C%E3%81%AE-primal-network-simplex-%E6%B3%95/images/%E3%83%9D%E3%83%86%E3%83%B3%E3%82%B7%E3%83%A3%E3%83%AB%E3%81%AE%E6%9B%B4%E6%96%B0_hu_914b68f877eae25.png","permalink":"https://miti-7.github.io/post/%E6%9C%80%E5%B0%8F%E8%B2%BB%E7%94%A8%E6%B5%81%E5%95%8F%E9%A1%8C%E3%81%AE-primal-network-simplex-%E6%B3%95/","title":"最小費用流問題の Primal Network Simplex 法"},{"content":"1. はじめに Green Hackenbush は以下のルールをもつ有限型不偏ゲームです．\n点線で表された地面，点，点と点を結ぶ有限個の辺からなる図形がある どの図形のどの部分も辺をたどると地面につながる 2 人のプレーヤーは交互に図形から 1 つの辺を選んで取り除く．選んだ辺を取り除くことで地面とつながらなくなってしまう部分は辺と同時に取り除かれる 最後の辺をとったプレーヤーの勝ち Green Hackenbush は有限型不偏ゲームなので各図形のグランディ数を求めることができます．今回は木と呼ばれる図形のグランディ数を求めていきます．\n節 2 と 節 3 では Green Hackenbush で一般に適用できる性質を確認します．節 4 と 節 5 ではこの性質を利用し具体的な図形のグランディ数を求める方法を示します．\n最後に節 6 で Green Hackenbush の木のグランディ数を求める問題を紹介します．\n2. 地面の点の移動 地面上にある点を移動してもゲームのグランディ数は変わらないので，自由に移動させることができます．\n3. コロン原理(Colon Principle) コロン原理\n図形 A のグランディ数を $g(A)$ とする．地面についている図形 $G$ と宙に浮いている図形 $H$ が 1 つの点 $a$ のみを共有してできる図形を $H \\cup_a G$ と表す．このとき，宙に浮いている図形 $H$，$K$ が $g(H) = g(K)$ を満たすならば，$g(H \\cup_a G) = g(K \\cup_a G)$ となる．\n証明\r$g(H \\cup_a G) = g(K \\cup_a G)$ ということは，$g(H \\cup_a G) \\ xor \\ g(K \\cup_a G) = 0$ なので，$H \\cup_a G と K \\cup_a G$ の直和ゲームは後手必勝と言い換えることができます．よって，「$g(H) = g(K)$ を満たすならば後手必勝」を示します． また，$H \\cup_a G$ と $K \\cup_a G$ は対称なので，$H \\cup_a G$ から辺を取り除く場合のみ考えます．\n先手の手は，「1. $G$ から辺を取り除く」，「2. $H$ から辺を取り除く」の 2 通りです．先手の各手について後手の必勝手を考えます． グランディ数の定義より，グランディ数 g の局面からはグランディ数 g 未満の局面に遷移できることを利用します．\n先手が $H \\cup_a G$ の $G$ から辺を取り除く場合\n後手は $K \\cup_a G$ の $G$ から同じ辺を取り除けばいい 先手が $H ∪_a G$ の $H$ から辺を取り除き，$H^\\prime $ にした場合\n$g(H^\\prime) \u0026lt; g(H)$ の場合\n仮定より $g(H) = g(K)$ なので，$K$ から辺を取り除いて移行できる $K^\\prime$ で，$g(K^\\prime) = g(H^\\prime)$ となるものがある．後手は $K → K^\\prime$ となる辺を取り除けばいい． $g(H^\\prime) \u0026gt; g(H)$ の場合\n$H^\\prime$ から辺を取り除いて移行できる $H^{\\prime \\prime}$ で， $g(H^{\\prime \\prime}) = g(H) = g(K)$ となるものがある．後手は $H^\\prime → H^{\\prime \\prime}$ となる辺を取り除けばいい． コロン原理を使うことで，ある 1 つの点のみを共有している宙に浮いている図形は，同じグランディ数を持つより単純な図形に置き換えることができます．\n4. 棒のグランディ数 まず，1 つの棒のみからなるゲームのグランディ数について考えます．\n長さ m の棒からは，長さ m 未満の棒に遷移できるため，長さ m の棒のグランディ数は m となります．\n次に，複数の棒からなるゲームのグランディ数を考えます．\n各棒は独立したゲームの局面とみなすことができるので，複数の棒からなるゲームのグランディ数は各棒のグランディ数の xor で求めることができます．\n例えば，長さ 1, 1, 2 の棒からなるゲームのグランディ数は $1 \\ xor \\ 1 \\ xor \\ 2 = 2$ となります．\n最後に，地面のある一点から複数の棒が伸びる図形のグランディ数を考えます．\n地面の点は自由に移動することができるため，地面のある一点から複数の棒が伸びる図形は，複数の棒からなるゲームに帰着することができます．\nよって，地面のある一点から複数の棒が伸びる図形のグランディ数は，各棒の長さの xor で求めることができます．\n5. 木のグランディ数 コロン原理を順次適用していくことによって，木のグランディ数を求めることができます．\n地面のある一点から複数の棒が伸びている図形のグランディ数は，各棒の長さの xor で求めることができました．コロン原理により，ある一点から複数の棒が伸びているような木の点は，各棒の長さの xor をとった値の長さの棒に変換することができます．この操作を繰り返すことで木のグランディ数を求めることができます．\n以下に例を示します．\n点 a からは，長さ 1 の棒と長さ 3 の棒が伸びています．よって，長さ 1 xor 3 = 2 の棒に置き換えることができます．\n点 b からは，長さ 1 の棒と長さ 3 の棒が伸びています．よって，長さ 1 xor 3 = 2 の棒に置き換えることができます．\n点 c からは，長さ 2 の棒と長さ 3 の棒と長さ 1 の棒が伸びています．よって，長さ 2 xor 3 xor 1 = 0 の棒に置き換えることができます．\n以上のことからこの木のグランディ数は 0 と求めることができました．\n6. AGC017 D - Game on Tree Green Hackenbush の木のグランディ数を求める問題として，D - Game on Tree があります．\nある頂点のグランディ数は，「自分の子のグランディ数 + 1」 の xor を使って求めことができるので，根から深さ優先探索をすることで木のグランディ数を求めることができます．\n提出コード\n参考 石取りゲームの数学 Hackenbush ","date":"2024-09-10T00:00:00+09:00","image":"https://miti-7.github.io/post/green-hackenbush-%E3%81%AE%E6%9C%A8%E3%81%AE%E3%82%B0%E3%83%A9%E3%83%B3%E3%83%87%E3%82%A3%E6%95%B0/images/%E3%82%B3%E3%83%AD%E3%83%B3%E5%8E%9F%E7%90%86%E3%81%AE%E4%BE%8B_hu_31ac073c42fae9ad.png","permalink":"https://miti-7.github.io/post/green-hackenbush-%E3%81%AE%E6%9C%A8%E3%81%AE%E3%82%B0%E3%83%A9%E3%83%B3%E3%83%87%E3%82%A3%E6%95%B0/","title":"Green Hackenbush の木のグランディ数"}]